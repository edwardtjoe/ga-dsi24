{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Standardized Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1\n",
    "\n",
    "Part 1 requires knowledge of basic Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher household income has been linked to higher education levels due to the capacity of parents to finance their children's tuition. As such, should education expenses be fully tax deductible? Is a state's exam score a resemblance of its median income?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAT and ACT are standardized tests that many colleges and universities in the United States require for their admissions process. This score is used along with other materials such as grade point average (GPA) and essay responses to determine whether or not a potential student will be accepted to the university.\n",
    "\n",
    "The SAT has two sections of the test: Evidence-Based Reading and Writing and Math ([*source*](https://www.princetonreview.com/college/sat-sections)). The ACT has 4 sections: English, Mathematics, Reading, and Science, with an additional optional writing section ([*source*](https://www.act.org/content/act/en/products-and-services/the-act/scores/understanding-your-scores.html)). They have different score ranges, which you can read more about on their websites or additional outside sources (a quick Google search will help you understand the scores for each test):\n",
    "* [SAT](https://collegereadiness.collegeboard.org/sat)\n",
    "* [ACT](https://www.act.org/content/act/en.html)\n",
    "\n",
    "Standardized tests have long been a controversial topic for students, administrators, and legislators. Since the 1940's, an increasing number of colleges have been using scores from sudents' performances on tests like the SAT and the ACT as a measure for college readiness and aptitude ([*source*](https://www.minotdailynews.com/news/local-news/2017/04/a-brief-history-of-the-sat-and-act/)). Supporters of these tests argue that these scores can be used as an objective measure to determine college admittance. Opponents of these tests claim that these tests are not accurate measures of students potential or ability and serve as an inequitable barrier to entry. Lately, more and more schools are opting to drop the SAT/ACT requirement for their Fall 2021 applications ([*read more about this here*](https://www.cnn.com/2020/04/14/us/coronavirus-colleges-sat-act-test-trnd/index.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell (or edit the above cell) with any other background or information that is necessary for your problem statement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Data\n",
    "\n",
    "There are 10 datasets included in the [`data`](./data/) folder for this project. You are required to pick **at least two** of these to complete your analysis. Feel free to use more than two if you would like, or add other relevant datasets you find online.\n",
    "\n",
    "* [`act_2017.csv`](./data/act_2017.csv): 2017 ACT Scores by State\n",
    "* [`act_2018.csv`](./data/act_2018.csv): 2018 ACT Scores by State\n",
    "* [`act_2019.csv`](./data/act_2019.csv): 2019 ACT Scores by State\n",
    "* [`act_2019_ca.csv`](./data/act_2019_ca.csv): 2019 ACT Scores in California by School\n",
    "* [`sat_2017.csv`](./data/sat_2017.csv): 2017 SAT Scores by State\n",
    "* [`sat_2018.csv`](./data/sat_2018.csv): 2018 SAT Scores by State\n",
    "* [`sat_2019.csv`](./data/sat_2019.csv): 2019 SAT Scores by State\n",
    "* [`sat_2019_by_intended_college_major.csv`](./data/sat_2019_by_intended_college_major.csv): 2019 SAT Scores by Intended College Major\n",
    "* [`sat_2019_ca.csv`](./data/sat_2019_ca.csv): 2019 SAT Scores in California by School\n",
    "* [`sat_act_by_college.csv`](./data/sat_act_by_college.csv): Ranges of Accepted ACT & SAT Student Scores by Colleges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets used:\n",
    "\n",
    "1. act_2017.csv: 2017 ACT Scores by State\n",
    "2. act_2018.csv: 2018 ACT Scores by State\n",
    "3. sat_2017.csv: 2017 SAT Scores by State\n",
    "4. sat_2018.csv: 2018 SAT Scores by State\n",
    "5. Median_Income_2017_2018.csv: 2017 and 2018 Median Household Income by State\n",
    "Source: https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on state policies or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code:\n",
    "\n",
    "numbers_list = [10, 12, 20, 22, 34, 40]\n",
    "\n",
    "def find_mean(list_of_numbers):\n",
    "    count = 0\n",
    "    total_sum = 0\n",
    "    for number in list_of_numbers:\n",
    "        total_sum += number\n",
    "        count += 1\n",
    "    return total_sum / count\n",
    "\n",
    "find_mean(numbers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.878112581387146"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code:\n",
    "\n",
    "numbers_list = [10, 12, 20, 22, 34, 40]\n",
    "\n",
    "def find_std(list_of_numbers):\n",
    "    list_mean = find_mean(list_of_numbers)\n",
    "    sum_std = 0\n",
    "    for number in list_of_numbers:\n",
    "        sum_std += ( 1 / len(list_of_numbers) ) * ((number - list_mean) ** 2)\n",
    "    result = sum_std ** (0.5)\n",
    "    return result\n",
    "        \n",
    "find_std(numbers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning function:\n",
    "    \n",
    "    Write a function that takes in a string that is a number and a percent symbol (ex. '50%', '30.5%', etc.) and converts this to a float that is the decimal approximation of the percent. For example, inputting '50%' in your function should return 0.5, '30.5%' should return 0.305, etc. Make sure to test your function to make sure it works!\n",
    "\n",
    "You will use these functions later on in the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.305, 0.421]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code:\n",
    "\n",
    "string_list = [\"50%\", \"30.5%\", \"42.1%\"]\n",
    "\n",
    "def decimal_approx(list_of_strings):\n",
    "    result = []\n",
    "    for i in list_of_strings:\n",
    "        result.append(round(float(i.strip(\"%\"))/100, 3))\n",
    "    return result\n",
    "\n",
    "decimal_approx(string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to edit state names.\n",
    "# Replaces space into underscore\n",
    "# Lowecases all letters\n",
    "\n",
    "def name_edits(list_state_name):\n",
    "    for name in list_state_name:\n",
    "        list_state_name = [name.lower().replace(\" \", \"_\") for name in list_state_name]\n",
    "    return list_state_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "# Data used are: \n",
    "act_2017 = pd.read_csv(\"../data/act_2017.csv\") # rows: 52, cols: 7. Has National\n",
    "act_2018 = pd.read_csv(\"../data/act_2018.csv\") # rows: 52, cols: 3. Has extra Maine\n",
    "sat_2017 = pd.read_csv(\"../data/sat_2017.csv\") # rows: 51, cols: 5\n",
    "sat_2018 = pd.read_csv(\"../data/sat_2018.csv\") # rows: 51, cols: 5\n",
    "\n",
    "# when:\n",
    "# col: 3 = State, Participation, Composite\n",
    "# col: 7 = col 3 + English, Math, Reading, Science\n",
    "# col: 5 = State, Participation, Evidence-Based Reading and Writing, Math, Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Participation  English  Math  Reading  Science Composite\n",
       "0  National           60%     20.3  20.7     21.4     21.0      21.0\n",
       "1   Alabama          100%     18.9  18.4     19.7     19.4      19.2\n",
       "2    Alaska           65%     18.7  19.8     20.4     19.9      19.8\n",
       "3   Arizona           62%     18.6  19.8     20.1     19.8      19.7\n",
       "4  Arkansas          100%     18.9  19.0     19.7     19.5      19.4"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_2017_part</th>\n",
       "      <th>act_2017_eng</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_read</th>\n",
       "      <th>act_2017_sci</th>\n",
       "      <th>act_2017_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.651538</td>\n",
       "      <td>20.919231</td>\n",
       "      <td>21.173077</td>\n",
       "      <td>22.001923</td>\n",
       "      <td>21.040385</td>\n",
       "      <td>21.509615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.318325</td>\n",
       "      <td>2.332132</td>\n",
       "      <td>1.963602</td>\n",
       "      <td>2.048672</td>\n",
       "      <td>3.151113</td>\n",
       "      <td>2.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>17.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>19.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>20.550000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>21.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>22.525000</td>\n",
       "      <td>23.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       act_2017_part  act_2017_eng  act_2017_math  act_2017_read  \\\n",
       "count      52.000000     52.000000      52.000000      52.000000   \n",
       "mean        0.651538     20.919231      21.173077      22.001923   \n",
       "std         0.318325      2.332132       1.963602       2.048672   \n",
       "min         0.080000     16.300000      18.000000      18.100000   \n",
       "25%         0.310000     19.000000      19.400000      20.475000   \n",
       "50%         0.680000     20.550000      20.900000      21.700000   \n",
       "75%         1.000000     23.300000      23.100000      24.125000   \n",
       "max         1.000000     25.500000      25.300000      26.000000   \n",
       "\n",
       "       act_2017_sci  act_2017_comp  \n",
       "count     52.000000      52.000000  \n",
       "mean      21.040385      21.509615  \n",
       "std        3.151113       2.002083  \n",
       "min        2.300000      17.800000  \n",
       "25%       19.900000      19.800000  \n",
       "50%       21.150000      21.400000  \n",
       "75%       22.525000      23.600000  \n",
       "max       24.900000      25.500000  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   state          52 non-null     object \n",
      " 1   act_2017_part  52 non-null     float64\n",
      " 2   act_2017_eng   52 non-null     float64\n",
      " 3   act_2017_math  52 non-null     float64\n",
      " 4   act_2017_read  52 non-null     float64\n",
      " 5   act_2017_sci   52 non-null     float64\n",
      " 6   act_2017_comp  52 non-null     float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_2017_part</th>\n",
       "      <th>act_2017_eng</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_read</th>\n",
       "      <th>act_2017_sci</th>\n",
       "      <th>act_2017_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.651538</td>\n",
       "      <td>20.919231</td>\n",
       "      <td>21.173077</td>\n",
       "      <td>22.001923</td>\n",
       "      <td>21.453846</td>\n",
       "      <td>21.509615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.318325</td>\n",
       "      <td>2.332132</td>\n",
       "      <td>1.963602</td>\n",
       "      <td>2.048672</td>\n",
       "      <td>1.737303</td>\n",
       "      <td>2.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>17.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>19.975000</td>\n",
       "      <td>19.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>20.550000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>21.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>23.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       act_2017_part  act_2017_eng  act_2017_math  act_2017_read  \\\n",
       "count      52.000000     52.000000      52.000000      52.000000   \n",
       "mean        0.651538     20.919231      21.173077      22.001923   \n",
       "std         0.318325      2.332132       1.963602       2.048672   \n",
       "min         0.080000     16.300000      18.000000      18.100000   \n",
       "25%         0.310000     19.000000      19.400000      20.475000   \n",
       "50%         0.680000     20.550000      20.900000      21.700000   \n",
       "75%         1.000000     23.300000      23.100000      24.125000   \n",
       "max         1.000000     25.500000      25.300000      26.000000   \n",
       "\n",
       "       act_2017_sci  act_2017_comp  \n",
       "count     52.000000      52.000000  \n",
       "mean      21.453846      21.509615  \n",
       "std        1.737303       2.002083  \n",
       "min       18.200000      17.800000  \n",
       "25%       19.975000      19.800000  \n",
       "50%       21.300000      21.400000  \n",
       "75%       23.200000      23.600000  \n",
       "max       24.900000      25.500000  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Cleaning act_2017 data:\n",
    "act_2017.info()\n",
    "\n",
    "# 1. First, find out why composite is an object.\n",
    "# Then, find and replace string with number\n",
    "for value in act_2017[\"Composite\"]:\n",
    "    try:\n",
    "        float(value)\n",
    "    except:\n",
    "        print(value, \"is a string\")\n",
    "        print(act_2017.loc[act_2017[\"Composite\"] == value])\n",
    "        \n",
    "# 2. Change type from object to float\n",
    "act_2017.loc[act_2017[\"State\"] == \"Wyoming\", \"Composite\"] = 20.2\n",
    "act_2017[\"Composite\"] = pd.to_numeric(act_2017[\"Composite\"])\n",
    "\n",
    "# 3. Rename to lowercase and shorter name. Remember to describe later on.\n",
    "act_2017.rename(columns={\"State\": \"state\",\n",
    "                         \"Participation\": \"act_2017_part\",\n",
    "                         \"English\": \"act_2017_eng\",\n",
    "                         \"Math\": \"act_2017_math\",\n",
    "                         \"Reading\": \"act_2017_read\",\n",
    "                         \"Science\": \"act_2017_sci\",\n",
    "                         \"Composite\": \"act_2017_comp\"\n",
    "                        }, inplace=True)\n",
    "\n",
    "# 4. Change participation into floats using the function made from Q1(b)\n",
    "act_2017[\"act_2017_part\"] = decimal_approx(act_2017[\"act_2017_part\"])\n",
    "\n",
    "# 5. Renaming states into lowercase and replacing spaces to underscore\n",
    "# using function above\n",
    "act_2017[\"state\"] = name_edits(act_2017[\"state\"])\n",
    "\n",
    "# 6. Maryland's science score is an anomaly, \n",
    "# therefore we derive it from the available data.\n",
    "act_2017.loc[act_2017[\"state\"] == \"maryland\", \"act_2017_sci\"]\n",
    "act_2017.loc[act_2017[\"state\"] == \"maryland\", \"act_2017_sci\"] = \\\n",
    "    act_2017.loc[act_2017[\"state\"] == \"maryland\", \"act_2017_comp\"] * 4 \\\n",
    "    - act_2017.loc[act_2017[\"state\"] == \"maryland\", \"act_2017_read\"] \\\n",
    "    - act_2017.loc[act_2017[\"state\"] == \"maryland\", \"act_2017_math\"] \\\n",
    "    - act_2017.loc[act_2017[\"state\"] == \"maryland\", \"act_2017_eng\"]\n",
    "\n",
    "act_2017.info()\n",
    "act_2017.head()\n",
    "act_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33%</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66%</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27%</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Composite\n",
       "0     Alabama          100%       19.1\n",
       "1      Alaska           33%       20.8\n",
       "2     Arizona           66%       19.2\n",
       "3    Arkansas          100%       19.4\n",
       "4  California           27%       22.7"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   Composite      52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   state          51 non-null     object \n",
      " 1   act_2018_part  51 non-null     float64\n",
      " 2   act_2018_comp  51 non-null     float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_2018_part</th>\n",
       "      <th>act_2018_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alaska</td>\n",
       "      <td>0.33</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arizona</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  act_2018_part  act_2018_comp\n",
       "0     alabama           1.00           19.1\n",
       "1      alaska           0.33           20.8\n",
       "2     arizona           0.66           19.2\n",
       "3    arkansas           1.00           19.4\n",
       "4  california           0.27           22.7"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Cleaning act_2018 data:\n",
    "\n",
    "act_2018.info()\n",
    "\n",
    "# 1. Rename to lowercase and shorter name. Remember to describe later on.\n",
    "act_2018.rename(columns={\"State\": \"state\",\n",
    "                         \"Participation\": \"act_2018_part\",\n",
    "                         \"Composite\": \"act_2018_comp\"\n",
    "                        }, inplace=True)\n",
    "\n",
    "# 2. Change participation into floats using the function made from Q1(b)\n",
    "act_2018[\"act_2018_part\"] = decimal_approx(act_2018[\"act_2018_part\"])\n",
    "\n",
    "# 3. Renaming states into lowercase and replacing spaces to underscore\n",
    "# using function above\n",
    "act_2018[\"state\"] = name_edits(act_2018[\"state\"])\n",
    "\n",
    "# 4. There are two \"Maine\" entries. Need to drop one, then reset_index.\n",
    "# Remember to inplace=True and drop=True to avoid duplicating\n",
    "act_2018[\"state\"].value_counts().sort_values(ascending=False).head()\n",
    "act_2018.drop(index=19, inplace=True)\n",
    "act_2018.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 5. Checking if data is sufficiently clean\n",
    "act_2018.info()\n",
    "act_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama            5%                                 593   572   1165\n",
       "1      Alaska           38%                                 547   533   1080\n",
       "2     Arizona           30%                                 563   553   1116\n",
       "3    Arkansas            3%                                 614   594   1208\n",
       "4  California           53%                                 531   524   1055"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   state                51 non-null     object \n",
      " 1   sat_2017_part        51 non-null     float64\n",
      " 2   sat_2017_read_write  51 non-null     int64  \n",
      " 3   sat_2017_math        51 non-null     int64  \n",
      " 4   sat_2017_total       51 non-null     int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_2017_part</th>\n",
       "      <th>sat_2017_read_write</th>\n",
       "      <th>sat_2017_math</th>\n",
       "      <th>sat_2017_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.398039</td>\n",
       "      <td>569.117647</td>\n",
       "      <td>556.882353</td>\n",
       "      <td>1126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352766</td>\n",
       "      <td>45.666901</td>\n",
       "      <td>47.121395</td>\n",
       "      <td>92.487621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>533.500000</td>\n",
       "      <td>523.500000</td>\n",
       "      <td>1055.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.380000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.660000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>1211.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>1295.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sat_2017_part  sat_2017_read_write  sat_2017_math  sat_2017_total\n",
       "count      51.000000            51.000000      51.000000       51.000000\n",
       "mean        0.398039           569.117647     556.882353     1126.000000\n",
       "std         0.352766            45.666901      47.121395       92.487621\n",
       "min         0.020000           482.000000     468.000000      950.000000\n",
       "25%         0.040000           533.500000     523.500000     1055.500000\n",
       "50%         0.380000           559.000000     548.000000     1106.000000\n",
       "75%         0.660000           613.000000     599.000000     1211.500000\n",
       "max         1.000000           644.000000     651.000000     1295.000000"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Cleaning sat_2017 data:\n",
    "\n",
    "sat_2017.info()\n",
    "\n",
    "# 1. Rename to lowercase and shorter name. Remember to describe later on.\n",
    "sat_2017.rename(columns={\"State\": \"state\",\n",
    "                         \"Participation\": \"sat_2017_part\",\n",
    "                         \"Total\": \"sat_2017_total\",\n",
    "                         \"Evidence-Based Reading and Writing\": \"sat_2017_read_write\",\n",
    "                         \"Math\": \"sat_2017_math\"\n",
    "                        }, inplace=True)\n",
    "\n",
    "# 2. Renaming states into lowercase and replacing spaces to underscore\n",
    "# using function above\n",
    "sat_2017[\"state\"] = name_edits(sat_2017[\"state\"])\n",
    "\n",
    "# 3. Change participation into floats using the function made from Q1(b)\n",
    "sat_2017[\"sat_2017_part\"] = decimal_approx(sat_2017[\"sat_2017_part\"])\n",
    "\n",
    "# 4. Maryland's math data is an anomaly. Let's derive it from the Total\n",
    "sat_2017[\"sat_2017_math\"].sort_values(ascending=True) \n",
    "sat_2017.loc[sat_2017[\"sat_2017_math\"] == 52, \"state\"] # Find state with math = 52\n",
    "sat_2017.loc[sat_2017[\"state\"] == \"maryland\", \"sat_2017_math\"] = \\\n",
    "    sat_2017.loc[sat_2017[\"state\"] == \"maryland\", \"sat_2017_total\"]\\\n",
    "    - sat_2017.loc[sat_2017[\"state\"] == \"maryland\", \"sat_2017_read_write\"]\n",
    "\n",
    "# 5. Fixing Total\n",
    "# Try summing up. 15 of the Totals are not the sum of R&W + Math.\n",
    "sat_2017.loc[sat_2017[\"sat_2017_math\"] + sat_2017[\"sat_2017_read_write\"]\\\n",
    "             != sat_2017[\"sat_2017_total\"], \"state\"]    # Found 15 Totals not matched\n",
    "# Fixing total = math + read_write\n",
    "sat_2017[\"sat_2017_total\"] = sat_2017[\"sat_2017_math\"] + sat_2017[\"sat_2017_read_write\"]\n",
    "\n",
    "# 6. Checking if data is sufficiently clean\n",
    "sat_2017.head()\n",
    "sat_2017.info()\n",
    "sat_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6%</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43%</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29%</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5%</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60%</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama            6%                                 595   571   1166\n",
       "1      Alaska           43%                                 562   544   1106\n",
       "2     Arizona           29%                                 577   572   1149\n",
       "3    Arkansas            5%                                 592   576   1169\n",
       "4  California           60%                                 540   536   1076"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   state                51 non-null     object \n",
      " 1   sat_2018_part        51 non-null     float64\n",
      " 2   sat_2018_read_write  51 non-null     int64  \n",
      " 3   sat_2018_math        51 non-null     int64  \n",
      " 4   sat_2018_total       51 non-null     int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_2018_part</th>\n",
       "      <th>sat_2018_read_write</th>\n",
       "      <th>sat_2018_math</th>\n",
       "      <th>sat_2018_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alaska</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arizona</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arkansas</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  sat_2018_part  sat_2018_read_write  sat_2018_math  \\\n",
       "0     alabama           0.06                  595            571   \n",
       "1      alaska           0.43                  562            544   \n",
       "2     arizona           0.29                  577            572   \n",
       "3    arkansas           0.05                  592            576   \n",
       "4  california           0.60                  540            536   \n",
       "\n",
       "   sat_2018_total  \n",
       "0            1166  \n",
       "1            1106  \n",
       "2            1149  \n",
       "3            1168  \n",
       "4            1076  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Cleaning sat_2017 data:\n",
    "\n",
    "sat_2018.describe()\n",
    "\n",
    "# 1. Rename to lowercase and shorter name. Remember to describe later on.\n",
    "sat_2018.rename(columns={\"State\": \"state\",\n",
    "                         \"Participation\": \"sat_2018_part\",\n",
    "                         \"Total\": \"sat_2018_total\",\n",
    "                         \"Evidence-Based Reading and Writing\": \"sat_2018_read_write\",\n",
    "                         \"Math\": \"sat_2018_math\"\n",
    "                        }, inplace=True)\n",
    "\n",
    "# 2. Renaming states into lowercase and replacing spaces to underscore\n",
    "# using function above\n",
    "sat_2018[\"state\"] = name_edits(sat_2018[\"state\"])\n",
    "\n",
    "# 3. Change participation into floats using the function made from Q1(b)\n",
    "sat_2018[\"sat_2018_part\"] = decimal_approx(sat_2018[\"sat_2018_part\"])\n",
    "\n",
    "# 4. Fixing Total\n",
    "# Try summing up. 9 of the totals are not the sum of read_write + math.\n",
    "# Fixing total = math + read_write\n",
    "sat_2018.loc[sat_2018[\"sat_2018_math\"] + sat_2018[\"sat_2018_read_write\"]\\\n",
    "            != sat_2018[\"sat_2018_total\"], \"state\"] # Found 9\n",
    "sat_2018[\"sat_2018_total\"] = sat_2018[\"sat_2018_math\"] \\\n",
    "                           + sat_2018[\"sat_2018_read_write\"]\n",
    "\n",
    "# 5. Checking if data is sufficiently clean\n",
    "sat_2018.info()\n",
    "sat_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# act_2017.shape # 52, 7\n",
    "# act_2018.shape # 51, 3\n",
    "# sat_2017.shape # 51, 5\n",
    "# sat_2018.shape # 51, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_2017_part</th>\n",
       "      <th>act_2017_eng</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_read</th>\n",
       "      <th>act_2017_sci</th>\n",
       "      <th>act_2017_comp</th>\n",
       "      <th>act_2018_part</th>\n",
       "      <th>act_2018_comp</th>\n",
       "      <th>sat_2017_part</th>\n",
       "      <th>sat_2017_read_write</th>\n",
       "      <th>sat_2017_math</th>\n",
       "      <th>sat_2017_total</th>\n",
       "      <th>sat_2018_part</th>\n",
       "      <th>sat_2018_read_write</th>\n",
       "      <th>sat_2018_math</th>\n",
       "      <th>sat_2018_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.651538</td>\n",
       "      <td>20.919231</td>\n",
       "      <td>21.173077</td>\n",
       "      <td>22.001923</td>\n",
       "      <td>21.453846</td>\n",
       "      <td>21.509615</td>\n",
       "      <td>0.617255</td>\n",
       "      <td>21.496078</td>\n",
       "      <td>0.398039</td>\n",
       "      <td>569.117647</td>\n",
       "      <td>556.882353</td>\n",
       "      <td>1126.000000</td>\n",
       "      <td>0.457451</td>\n",
       "      <td>563.686275</td>\n",
       "      <td>556.235294</td>\n",
       "      <td>1119.921569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.318325</td>\n",
       "      <td>2.332132</td>\n",
       "      <td>1.963602</td>\n",
       "      <td>2.048672</td>\n",
       "      <td>1.737303</td>\n",
       "      <td>2.002083</td>\n",
       "      <td>0.340371</td>\n",
       "      <td>2.111583</td>\n",
       "      <td>0.352766</td>\n",
       "      <td>45.666901</td>\n",
       "      <td>47.121395</td>\n",
       "      <td>92.487621</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>47.502627</td>\n",
       "      <td>47.772623</td>\n",
       "      <td>94.189138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>19.975000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>19.950000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>533.500000</td>\n",
       "      <td>523.500000</td>\n",
       "      <td>1055.500000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>534.500000</td>\n",
       "      <td>522.500000</td>\n",
       "      <td>1058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>20.550000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>544.000000</td>\n",
       "      <td>1097.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.650000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>1211.500000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>610.500000</td>\n",
       "      <td>593.500000</td>\n",
       "      <td>1204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>1295.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>1298.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       act_2017_part  act_2017_eng  act_2017_math  act_2017_read  \\\n",
       "count      52.000000     52.000000      52.000000      52.000000   \n",
       "mean        0.651538     20.919231      21.173077      22.001923   \n",
       "std         0.318325      2.332132       1.963602       2.048672   \n",
       "min         0.080000     16.300000      18.000000      18.100000   \n",
       "25%         0.310000     19.000000      19.400000      20.475000   \n",
       "50%         0.680000     20.550000      20.900000      21.700000   \n",
       "75%         1.000000     23.300000      23.100000      24.125000   \n",
       "max         1.000000     25.500000      25.300000      26.000000   \n",
       "\n",
       "       act_2017_sci  act_2017_comp  act_2018_part  act_2018_comp  \\\n",
       "count     52.000000      52.000000      51.000000      51.000000   \n",
       "mean      21.453846      21.509615       0.617255      21.496078   \n",
       "std        1.737303       2.002083       0.340371       2.111583   \n",
       "min       18.200000      17.800000       0.070000      17.700000   \n",
       "25%       19.975000      19.800000       0.285000      19.950000   \n",
       "50%       21.300000      21.400000       0.660000      21.300000   \n",
       "75%       23.200000      23.600000       1.000000      23.650000   \n",
       "max       24.900000      25.500000       1.000000      25.600000   \n",
       "\n",
       "       sat_2017_part  sat_2017_read_write  sat_2017_math  sat_2017_total  \\\n",
       "count      51.000000            51.000000      51.000000       51.000000   \n",
       "mean        0.398039           569.117647     556.882353     1126.000000   \n",
       "std         0.352766            45.666901      47.121395       92.487621   \n",
       "min         0.020000           482.000000     468.000000      950.000000   \n",
       "25%         0.040000           533.500000     523.500000     1055.500000   \n",
       "50%         0.380000           559.000000     548.000000     1106.000000   \n",
       "75%         0.660000           613.000000     599.000000     1211.500000   \n",
       "max         1.000000           644.000000     651.000000     1295.000000   \n",
       "\n",
       "       sat_2018_part  sat_2018_read_write  sat_2018_math  sat_2018_total  \n",
       "count      51.000000            51.000000      51.000000       51.000000  \n",
       "mean        0.457451           563.686275     556.235294     1119.921569  \n",
       "std         0.373143            47.502627      47.772623       94.189138  \n",
       "min         0.020000           480.000000     480.000000      977.000000  \n",
       "25%         0.045000           534.500000     522.500000     1058.000000  \n",
       "50%         0.520000           552.000000     544.000000     1097.000000  \n",
       "75%         0.775000           610.500000     593.500000     1204.000000  \n",
       "max         1.000000           643.000000     655.000000     1298.000000  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging\n",
    "\n",
    "df = act_2017.merge(act_2018, on = \"state\", how = \"outer\")\\\n",
    "             .merge(sat_2017, on = \"state\", how = \"outer\")\\\n",
    "             .merge(sat_2018, on = \"state\", how = \"outer\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping national\n",
    "df.drop(index=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>2018_median_income</th>\n",
       "      <th>2017_median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>49,936</td>\n",
       "      <td>50,865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alaska</td>\n",
       "      <td>68,734</td>\n",
       "      <td>77,987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arizona</td>\n",
       "      <td>62,283</td>\n",
       "      <td>59,700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state 2018_median_income 2017_median_income\n",
       "0  alabama             49,936             50,865\n",
       "1   alaska             68,734             77,987\n",
       "2  arizona             62,283             59,700"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean external dataset and merge\n",
    "\n",
    "med_inc = pd.read_csv(\"../data/Median_Income_2017_2018.csv\")\n",
    "\n",
    "# 1. Drop national average from list and reset index.\n",
    "med_inc.drop(index=0, inplace=True)\n",
    "med_inc.reset_index(drop=True, inplace=True)\n",
    "med_inc.head()\n",
    "\n",
    "# 2. Modify spaces into underscore and uppercase to lowercase.\n",
    "med_inc[\"state\"] = name_edits(med_inc[\"state\"])\n",
    "\n",
    "# 3. Rename column names for median income\n",
    "med_inc.rename(columns={\"2018\": \"2018_median_income\",\n",
    "                        \"2017\": \"2017_median_income\"},\\\n",
    "                        inplace=True)\n",
    "display(med_inc.head(3))\n",
    "\n",
    "# 4. Merging to df\n",
    "df = df.merge(med_inc, on=\"state\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_2017_part</th>\n",
       "      <th>act_2017_eng</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_read</th>\n",
       "      <th>act_2017_sci</th>\n",
       "      <th>act_2017_comp</th>\n",
       "      <th>act_2018_part</th>\n",
       "      <th>act_2018_comp</th>\n",
       "      <th>sat_2017_part</th>\n",
       "      <th>sat_2017_read_write</th>\n",
       "      <th>sat_2017_math</th>\n",
       "      <th>sat_2017_total</th>\n",
       "      <th>sat_2018_part</th>\n",
       "      <th>sat_2018_read_write</th>\n",
       "      <th>sat_2018_math</th>\n",
       "      <th>sat_2018_total</th>\n",
       "      <th>2018_median_income</th>\n",
       "      <th>2017_median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>49,936</td>\n",
       "      <td>50,865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.33</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>68,734</td>\n",
       "      <td>77,987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>62,283</td>\n",
       "      <td>59,700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  act_2017_part  act_2017_eng  act_2017_math  act_2017_read  \\\n",
       "0  alabama           1.00          18.9           18.4           19.7   \n",
       "1   alaska           0.65          18.7           19.8           20.4   \n",
       "2  arizona           0.62          18.6           19.8           20.1   \n",
       "\n",
       "   act_2017_sci  act_2017_comp  act_2018_part  act_2018_comp  sat_2017_part  \\\n",
       "0          19.4           19.2           1.00           19.1           0.05   \n",
       "1          19.9           19.8           0.33           20.8           0.38   \n",
       "2          19.8           19.7           0.66           19.2           0.30   \n",
       "\n",
       "   sat_2017_read_write  sat_2017_math  sat_2017_total  sat_2018_part  \\\n",
       "0                593.0          572.0          1165.0           0.06   \n",
       "1                547.0          533.0          1080.0           0.43   \n",
       "2                563.0          553.0          1116.0           0.29   \n",
       "\n",
       "   sat_2018_read_write  sat_2018_math  sat_2018_total 2018_median_income  \\\n",
       "0                595.0          571.0          1166.0             49,936   \n",
       "1                562.0          544.0          1106.0             68,734   \n",
       "2                577.0          572.0          1149.0             62,283   \n",
       "\n",
       "  2017_median_income  \n",
       "0             50,865  \n",
       "1             77,987  \n",
       "2             59,700  "
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**\n",
    "\n",
    "*Note*: if you are unsure of what a feature is, check the source of the data! This can be found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|column name|int/float/object|ACT/SAT|This is an example| \n",
    "|state|object|ACT&SAT|US State\n",
    "|act_2017_part|float|ACT|2017 Participation Rate\n",
    "|act_2017_eng|float|ACT|2017 English Score\n",
    "|act_2017_math|float|ACT|2017 Math Score\n",
    "|act_2017_read|float|ACT|2017 Reading Score\n",
    "|act_2017_sci|float|ACT|2017 Science Score\n",
    "|act_2017_comp|float|ACT|2017 Composite Score\n",
    "|act_2018_part|float|ACT|2018 Participation Rate\n",
    "|act_2018_comp|float|ACT|2018 Composite Score\n",
    "|sat_2017_part|float|SAT|2017 Participation Rate\n",
    "|sat_2017_read_write|int|SAT|2017 Evidence-Based Reading and Writing Score\n",
    "|sat_2017_math|int|SAT|2017 Math Score\n",
    "|sat_2017_total|int|SAT|2017 Total Score\n",
    "|sat_2018_part|float|SAT|2018 Participation Rate\n",
    "|sat_2018_read_write|int|SAT|2018 Evidence-Based Reading and Writing Score\n",
    "|sat_2018_math|int|SAT|2018 Math Score\n",
    "|sat_2018_total|int|SAT|2018 Total Score\n",
    "|2017_median_income|int|N/A|2017 Median Household Income by State\n",
    "|2018_median_income|int|N/A|2018 Median Household Income by State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "        - Do any states show have >50% participation on *both* tests each year?\n",
    "        - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "        - Which California school districts have the highest and lowest mean test scores?\n",
    "    - **You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = {i: find_std(df[i]) for i in df.columns[1:]}\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_2017_part</th>\n",
       "      <th>act_2017_eng</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_read</th>\n",
       "      <th>act_2017_sci</th>\n",
       "      <th>act_2017_comp</th>\n",
       "      <th>act_2018_part</th>\n",
       "      <th>act_2018_comp</th>\n",
       "      <th>sat_2017_part</th>\n",
       "      <th>sat_2017_read_write</th>\n",
       "      <th>sat_2017_math</th>\n",
       "      <th>sat_2017_total</th>\n",
       "      <th>sat_2018_part</th>\n",
       "      <th>sat_2018_read_write</th>\n",
       "      <th>sat_2018_math</th>\n",
       "      <th>sat_2018_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>wyoming</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>626.00000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>1230.00000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>633.00000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>stdev</td>\n",
       "      <td>0.318242</td>\n",
       "      <td>2.330488</td>\n",
       "      <td>1.962462</td>\n",
       "      <td>2.046903</td>\n",
       "      <td>1.736117</td>\n",
       "      <td>2.000786</td>\n",
       "      <td>0.337017</td>\n",
       "      <td>2.090779</td>\n",
       "      <td>0.349291</td>\n",
       "      <td>45.21697</td>\n",
       "      <td>46.657134</td>\n",
       "      <td>91.57639</td>\n",
       "      <td>0.369466</td>\n",
       "      <td>47.03461</td>\n",
       "      <td>47.301946</td>\n",
       "      <td>93.261144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  act_2017_part  act_2017_eng  act_2017_math  act_2017_read  \\\n",
       "50  wyoming       1.000000     19.400000      19.800000      20.800000   \n",
       "51    stdev       0.318242      2.330488       1.962462       2.046903   \n",
       "\n",
       "    act_2017_sci  act_2017_comp  act_2018_part  act_2018_comp  sat_2017_part  \\\n",
       "50     20.600000      20.200000       1.000000      20.000000       0.030000   \n",
       "51      1.736117       2.000786       0.337017       2.090779       0.349291   \n",
       "\n",
       "    sat_2017_read_write  sat_2017_math  sat_2017_total  sat_2018_part  \\\n",
       "50            626.00000     604.000000      1230.00000       0.030000   \n",
       "51             45.21697      46.657134        91.57639       0.369466   \n",
       "\n",
       "    sat_2018_read_write  sat_2018_math  sat_2018_total  \n",
       "50            633.00000     625.000000     1258.000000  \n",
       "51             47.03461      47.301946       93.261144  "
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "sd = [\"stdev\"]\n",
    "column_names = ['act_2017_part', 'act_2017_eng', 'act_2017_math',\n",
    "       'act_2017_read', 'act_2017_sci', 'act_2017_comp', 'act_2018_part',\n",
    "       'act_2018_comp', 'sat_2017_part', 'sat_2017_read_write',\n",
    "       'sat_2017_math', 'sat_2017_total', 'sat_2018_part',\n",
    "       'sat_2018_read_write', 'sat_2018_math', 'sat_2018_total']\n",
    "\n",
    "for i in column_names:\n",
    "    sd.append(find_std(df[i]))\n",
    "\n",
    "\n",
    "df.loc[len(df.index)] = sd\n",
    "\n",
    "# df.drop(51, inplace=True)\n",
    "\n",
    "df.tail(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Observation 1: Highest participation on act and sat for 2017 and 2018\n",
    "display(df.sort_values([\"act_2017_part\", \"act_2018_part\"], ascending=False)\\\n",
    "        [[\"state\", \"act_2017_part\", \"act_2018_part\"]].head(20))\n",
    "display(df.sort_values([\"sat_2017_part\", \"sat_2018_part\"], ascending=False)\\\n",
    "        [[\"state\", \"sat_2017_part\", \"sat_2018_part\"]].head(5))\n",
    "display(df.sort_values(\"act_2017_part\", ascending=False)\\\n",
    "        [[\"state\", \"act_2017_part\"]].head(8))\n",
    "display(df.sort_values(\"act_2018_part\", ascending=False)\\\n",
    "        [[\"state\", \"act_2018_part\"]].head(8))\n",
    "display(df.sort_values(\"sat_2017_part\", ascending=False)\\\n",
    "        [[\"state\", \"sat_2017_part\"]].head(5))\n",
    "display(df.sort_values(\"sat_2018_part\", ascending=False)\\\n",
    "        [[\"state\", \"sat_2018_part\"]].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation 1: Almost all states which have the highest ACT participation rate in 2017 have the highest ACT participation rate in 2018.\n",
    "\n",
    "100% Participation in both 2017 and 2018 ACT: AL, AR, KY, LA, MS, MO, MT, NV, NC, OK, SC, TN, UT, WI, WY\n",
    "\n",
    "100% Participation in both 2017 and 2018 SAT: CT, DE, MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_2018_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>minnesota</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>north_dakota</td>\n",
       "      <td>1283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>iowa</td>\n",
       "      <td>1265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kansas</td>\n",
       "      <td>1264.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  sat_2018_total\n",
       "23     minnesota          1298.0\n",
       "49     wisconsin          1294.0\n",
       "34  north_dakota          1283.0\n",
       "15          iowa          1265.0\n",
       "16        kansas          1264.0"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for observation 2: States with highest mean composite or total in 2017 and 2018\n",
    "df.sort_values(\"act_2017_comp\", ascending=False)[[\"state\", \"act_2017_comp\"]].head(5)\n",
    "df.sort_values(\"act_2018_comp\", ascending=False)[[\"state\", \"act_2018_comp\"]].head(5)\n",
    "df.sort_values(\"sat_2017_total\", ascending=False)[[\"state\", \"sat_2017_total\"]].head(5)\n",
    "df.sort_values(\"sat_2018_total\", ascending=False)[[\"state\", \"sat_2018_total\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation 2: States with the highest composite score for 2017 ACT generally have the highest scores in 2018 ACT. This is also true for 2017 and 2018 SAT. In each examination, the top 4 out of 5 states with the highest score are the same.\n",
    "\n",
    "States which are in the top 5 of both years (2017 and 2018) are bolded below:\n",
    "\n",
    "act_2017_comp highest: **New Hampshire, Massachusetts, Connecticut**, Maine, **New York**\n",
    "\n",
    "act_2018_comp highest: **Connecticut, Massachusetts, New Hampshire, New York**, Michigan\n",
    "\n",
    "sat_2017_total highest: **Minnesota, Wisconsin, Iowa,** Missouri, **Kansas**\n",
    "\n",
    "sat_2018_total highest: **Minnesota, Wisconsin,** North Dakota, **Iowa, Kansas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hawaii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state\n",
       "9   florida\n",
       "10  georgia\n",
       "11   hawaii"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for observation 3: Which states have more than 50% participation rates in  \n",
    "# both exams (ACT and SAT) and both years (2017 and 2018)?\n",
    "rate = 0.5\n",
    "df.loc[(df[\"act_2017_part\"] > rate) & (df[\"act_2018_part\"] > rate)\\\n",
    "       & (df[\"sat_2017_part\"] > rate) & (df[\"sat_2018_part\"] > rate)][[\"state\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation 3: Only Florida, Georgia and Hawaii have more than 50% participation rates in both exams in both years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Make sure to answer your question of interest or address your problem statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your conclusions and recommendations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
