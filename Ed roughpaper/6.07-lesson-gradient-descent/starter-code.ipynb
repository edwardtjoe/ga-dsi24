{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Gradient Descent Code-Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through how gradient descent works using code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective function\n",
    "def f(x):\n",
    "    return -np.log(x) / (1 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative of the objective function\n",
    "\n",
    "def f_deriv(x):\n",
    "    return -(1 + 1/x - np.log(x)) / (1 + x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8b56735e50>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what it looks like\n",
    "\n",
    "xs = np.linspace(1, 7, 1000)\n",
    "plt.plot(xs, f(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial value and learning rate\n",
    "x = 1\n",
    "alpha = 1\n",
    "\n",
    "# Iterate and apply gradient descent\n",
    "x_steps = [x]\n",
    "for _ in range(100):\n",
    "    x = x - alpha * f_deriv(x)\n",
    "    x_steps.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8b56be01c0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot iterations\n",
    "plt.plot(x_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if we can do OLS by Gradient Descent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate data from a Poisson(45) distribution.\n",
    "temp = np.random.poisson(45, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View array.\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53, 38, 58, 46, 37, 54, 49, 42, 45, 51, 49, 55, 42, 46, 44, 41, 25,\n",
       "       52, 36, 51, 47, 30, 46, 45, 51, 44, 53, 43, 37, 46, 48, 46, 43, 42,\n",
       "       29, 53, 44, 45, 38, 43, 48, 42, 45, 48, 33, 58, 43, 44, 59, 38, 35,\n",
       "       34, 33, 53, 52, 36, 48, 50, 40, 50, 42, 42, 53, 50, 35, 45, 41, 43,\n",
       "       55, 60, 48, 41, 48, 51, 34, 31, 44, 42, 37, 47, 34, 33, 49, 42, 42,\n",
       "       51, 43, 35, 31, 36, 50, 63, 41, 33, 48, 44, 47, 29, 44, 40, 44, 47,\n",
       "       49, 41, 49, 56, 60, 47, 29, 42, 47, 53, 43, 53, 44, 61, 39, 47, 35,\n",
       "       45, 45, 46, 54, 36, 50, 49, 36, 42, 43, 55, 45, 43, 45, 45, 48, 33,\n",
       "       36, 36, 38, 55, 48, 38, 37, 38, 36, 39, 45, 47, 32, 52, 38, 42, 47,\n",
       "       44, 27, 49, 45, 35, 46, 40, 39, 36, 47, 51, 34, 47, 44, 40, 48, 47,\n",
       "       35, 40, 38, 38, 33, 35, 52, 38, 57, 46, 51, 41, 45, 35, 41, 37, 46,\n",
       "       42, 41, 40, 50, 44, 42, 36, 58, 32, 46, 38, 37, 48, 42, 43, 44, 44,\n",
       "       50, 43, 56, 36, 47, 47, 55, 37, 40, 50, 42, 36, 51, 39, 49, 49, 40,\n",
       "       47, 44, 37, 45, 58, 49, 46, 43, 44, 54, 47, 31, 52, 42, 46, 42, 50,\n",
       "       39, 37, 45, 56, 47, 37, 45, 39, 39, 46, 51, 45, 43, 37, 42, 48, 49,\n",
       "       39, 51, 48, 35, 52, 48, 41, 39, 38, 43, 52, 40, 47, 47, 46, 41, 51,\n",
       "       54, 55, 43, 40, 48, 38, 36, 40, 48, 39, 54, 47, 38, 43, 45, 37, 34,\n",
       "       40, 41, 49, 46, 50, 47, 45, 42, 35, 50, 49, 40, 51, 40, 42, 56, 60,\n",
       "       38, 54, 52, 49, 40, 59, 38, 56, 49, 59, 53, 41, 39, 33, 42, 32, 46,\n",
       "       41, 54, 39, 54, 54, 58, 51, 45, 51, 43, 39, 42, 41, 28, 43, 51, 43,\n",
       "       59, 47, 59, 47, 39, 39, 51, 43, 49, 52, 39, 47, 40, 53, 48, 34, 42,\n",
       "       50, 33, 49, 53, 45, 52, 49, 40, 51, 49, 49, 47, 54, 52, 42, 37, 52,\n",
       "       48, 48, 51, 50, 63, 49, 41, 32, 42, 50, 50, 45, 49, 43, 37, 49, 34,\n",
       "       48, 60, 44, 43, 43, 55, 39, 48, 54, 65, 54, 50, 36, 57, 51, 36, 49,\n",
       "       38, 32, 40, 41, 43, 47, 49, 51, 45, 37, 47, 46, 41, 34, 26, 43, 46,\n",
       "       51, 37, 48, 30, 49, 49, 42, 46, 44, 45, 33, 40, 54, 38, 48, 46, 38,\n",
       "       33, 40, 54, 50, 42, 54, 44, 45, 55, 40, 56, 47, 50, 38, 66, 53, 40,\n",
       "       44, 42, 37, 65, 48, 51, 39, 38, 42, 44, 47, 37, 48, 47, 39, 40, 46,\n",
       "       28, 44, 41, 28, 48, 44, 45, 36, 41, 38, 65, 48, 54, 49, 59, 45, 54,\n",
       "       49, 39, 43, 35, 54, 46, 54, 41, 52, 51, 52, 46, 41, 43, 43, 39, 39,\n",
       "       47, 47, 43, 45, 43, 47, 47, 52, 61, 38, 48, 40, 42, 45, 40, 52, 41,\n",
       "       49, 43, 38, 38, 49, 46, 63, 52, 60, 39, 47, 42, 51, 52, 48, 47, 47,\n",
       "       39, 47, 39, 47, 49, 44, 36, 50, 40, 34, 38, 39, 32, 39, 54, 46, 42,\n",
       "       46, 44, 46, 38, 38, 34, 50, 48, 57, 43, 46, 45, 34, 36, 51, 40, 46,\n",
       "       43, 47, 56, 39, 36, 43, 51, 33, 38, 48, 57, 47, 38, 43, 42, 41, 44,\n",
       "       48, 47, 37, 51, 37, 41, 49, 52, 41, 45, 44, 42, 52, 51, 43, 50, 46,\n",
       "       62, 35, 44, 35, 37, 50, 42, 44, 51, 49, 40, 44, 48, 48, 32, 37, 45,\n",
       "       28, 49, 33, 42, 42, 48, 38, 48, 40, 34, 41, 47, 39, 47, 48, 51, 47,\n",
       "       52, 36, 57, 42, 44, 59, 36, 54, 41, 53, 56, 50, 53, 51, 38, 29, 36,\n",
       "       52, 45, 50, 47, 41, 48, 37, 35, 51, 46, 47, 42, 46, 50, 50, 62, 41,\n",
       "       41, 44, 54, 43, 49, 47, 51, 47, 48, 47, 46, 49, 40, 45, 31, 51, 51,\n",
       "       44, 41, 34, 47, 48, 48, 36, 53, 46, 38, 42, 40, 41, 40, 38, 44, 36,\n",
       "       50, 44, 51, 47, 50, 61, 31, 40, 56, 40, 44, 32, 26, 56, 46, 42, 58,\n",
       "       43, 40, 38, 44, 47, 35, 39, 53, 45, 53, 32, 46, 44, 53, 44, 48, 32,\n",
       "       52, 38, 37, 50, 39, 39, 44, 46, 35, 52, 39, 41, 46, 51, 56, 37, 51,\n",
       "       37, 48, 44, 34, 52, 64, 48, 54, 37, 46, 49, 33, 38, 52, 49, 44, 44,\n",
       "       45, 42, 49, 35, 37, 44, 48, 42, 48, 49, 49, 38, 39, 40, 49, 41, 54,\n",
       "       51, 40, 48, 35, 44, 46, 69, 43, 40, 41, 50, 50, 52, 54, 49, 34, 41,\n",
       "       41, 50, 55, 48, 55, 33, 51, 53, 47, 48, 54, 45, 41, 51, 55, 47, 47,\n",
       "       39, 35, 45, 60, 50, 48, 40, 44, 37, 45, 47, 39, 39, 35, 52, 45, 58,\n",
       "       34, 35, 45, 45, 40, 43, 56, 47, 52, 48, 40, 47, 35, 44, 36, 50, 33,\n",
       "       59, 49, 47, 47, 50, 55, 46, 41, 46, 36, 42, 48, 49, 48, 41, 44, 56,\n",
       "       41, 42, 49, 42, 44, 55, 37, 48, 42, 43, 49, 42, 49, 45, 43, 37, 50,\n",
       "       41, 36, 41, 47, 62, 43, 46, 46, 50, 44, 40, 31, 46, 47, 44, 45, 47,\n",
       "       47, 43, 44, 56, 46, 36, 36, 40, 59, 45, 47, 41, 50, 45, 46, 52, 46,\n",
       "       38, 53, 44, 47, 49, 49, 41, 52, 49, 41, 50, 50, 50, 48, 53, 34, 33,\n",
       "       43, 42, 45, 33, 51, 30, 43, 39, 43, 41, 39, 42, 36, 45, 47, 33, 39,\n",
       "       52, 46, 37, 40, 40, 48, 50, 29, 49, 53, 40, 41, 42, 53, 44, 34, 45,\n",
       "       48, 49, 60, 41, 51, 30, 61, 44, 39, 42, 51, 39, 44, 39])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.715\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean of array.\n",
    "print(np.mean(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ohio State Fun Facts:**\n",
    "1. Ohio Stadium can seat 104,944 people. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Ohio_Stadium).)\n",
    "2. Ohio Stadium's record attendance is 110,045 people. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Ohio_Stadium).)\n",
    "3. Ohio State is better than Michigan. (Source: It's just a fact.)\n",
    "4. Ohio State students enjoy soda. (Source: first-hand knowledge.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sodas ~ N(200000 + 1000 * temp, 20000)\n",
    "sodas_sold = 200000 + 1000 * temp + np.round(np.random.normal(0, 20000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240170., 247757., 294087., 242182., 251395., 228135., 229871.,\n",
       "       251448., 274682., 258112., 242739., 254986., 216992., 258090.,\n",
       "       261647., 231958., 215599., 257318., 227266., 249677., 288994.,\n",
       "       225059., 238833., 232049., 265884., 240376., 240013., 269426.,\n",
       "       265392., 233992., 210669., 266150., 229307., 257813., 189598.,\n",
       "       270852., 219777., 259615., 238285., 223921., 239859., 255726.,\n",
       "       247118., 259688., 272529., 226715., 275344., 246087., 241024.,\n",
       "       211394., 231218., 252433., 230449., 283223., 222976., 235758.,\n",
       "       222952., 257273., 257738., 241585., 189916., 245979., 261735.,\n",
       "       258086., 259716., 223579., 254604., 266850., 219428., 266393.,\n",
       "       237916., 239370., 254954., 241255., 220486., 231683., 222255.,\n",
       "       220283., 250587., 224024., 247326., 242252., 214484., 228449.,\n",
       "       265882., 231377., 233712., 244241., 246668., 230969., 238050.,\n",
       "       291447., 275778., 252577., 249706., 227835., 230391., 239450.,\n",
       "       252368., 268032., 257009., 216938., 270039., 221039., 241321.,\n",
       "       261004., 299913., 309198., 241134., 238336., 257690., 270753.,\n",
       "       236587., 288904., 248601., 270955., 252318., 255432., 251779.,\n",
       "       232655., 233834., 223997., 262790., 251579., 259155., 282490.,\n",
       "       235888., 255375., 221166., 247258., 258911., 259982., 239121.,\n",
       "       243568., 217643., 225859., 253808., 247504., 248013., 255995.,\n",
       "       248141., 224794., 250977., 246419., 245840., 228479., 201933.,\n",
       "       268943., 222423., 234744., 251870., 234160., 268199., 256340.,\n",
       "       240671., 221681., 269239., 240225., 238614., 242868., 203475.,\n",
       "       244173., 226413., 223947., 203553., 269254., 231415., 270675.,\n",
       "       237284., 212853., 212670., 264716., 234882., 227034., 236200.,\n",
       "       245036., 274348., 266970., 249805., 219479., 242731., 246206.,\n",
       "       225725., 215857., 247876., 236027., 246656., 226830., 236392.,\n",
       "       221515., 267804., 264705., 205076., 217410., 228069., 219000.,\n",
       "       244331., 209007., 218563., 227921., 246145., 244387., 229565.,\n",
       "       247536., 239066., 237567., 289469., 262809., 221008., 263595.,\n",
       "       271228., 214035., 256376., 280759., 219549., 217650., 271353.,\n",
       "       244430., 260030., 255812., 247814., 220471., 264946., 260392.,\n",
       "       240412., 257130., 218378., 256285., 254441., 242756., 276487.,\n",
       "       240318., 242292., 231607., 241529., 242513., 246506., 242609.,\n",
       "       236371., 253521., 236265., 223868., 281992., 264629., 219155.,\n",
       "       252794., 228941., 251270., 256884., 240312., 227325., 223189.,\n",
       "       223676., 231364., 247656., 224685., 264641., 277745., 223399.,\n",
       "       256788., 257994., 250440., 240519., 252854., 252645., 227247.,\n",
       "       257383., 264746., 231734., 246759., 254667., 246814., 275460.,\n",
       "       302277., 227280., 212379., 254076., 252431., 231383., 269065.,\n",
       "       221228., 252858., 241883., 281388., 277850., 227667., 234009.,\n",
       "       254192., 226257., 239092., 241508., 210607., 245723., 236205.,\n",
       "       237138., 273873., 216870., 251264., 244421., 243405., 255807.,\n",
       "       257801., 251412., 261364., 249374., 247755., 216297., 237492.,\n",
       "       310982., 273894., 212979., 232551., 247637., 266945., 259978.,\n",
       "       253901., 250491., 247558., 240718., 188614., 237404., 214972.,\n",
       "       249504., 300705., 261350., 232729., 272436., 263654., 266402.,\n",
       "       263137., 286131., 228382., 252473., 220472., 253110., 222626.,\n",
       "       219653., 237098., 270516., 261369., 234086., 248099., 244808.,\n",
       "       221830., 234660., 232830., 299534., 251659., 221448., 240705.,\n",
       "       259428., 288769., 208280., 215402., 285419., 241792., 224634.,\n",
       "       260693., 180285., 249068., 259556., 263485., 231722., 250714.,\n",
       "       221492., 256108., 231093., 240838., 227084., 267023., 269169.,\n",
       "       237308., 237765., 223028., 242006., 246996., 303416., 227761.,\n",
       "       292284., 268937., 246613., 267172., 249442., 257783., 248938.,\n",
       "       269471., 270929., 230486., 210615., 244940., 217999., 246730.,\n",
       "       284749., 234854., 242144., 244160., 271969., 194062., 235866.,\n",
       "       258226., 289002., 244162., 212469., 248394., 244293., 227207.,\n",
       "       223513., 245309., 225905., 187889., 257941., 266498., 256030.,\n",
       "       224246., 244970., 250870., 256976., 250367., 232317., 247640.,\n",
       "       250146., 263116., 240090., 258781., 247677., 279209., 245195.,\n",
       "       230778., 258067., 262958., 240139., 232410., 251932., 253264.,\n",
       "       248946., 239226., 273999., 275431., 241813., 266826., 225350.,\n",
       "       245959., 269186., 235639., 237047., 236958., 220207., 238305.,\n",
       "       236590., 216889., 255312., 258046., 237845., 277386., 260216.,\n",
       "       258612., 252843., 270091., 218161., 261805., 245437., 248065.,\n",
       "       241488., 230099., 262945., 220033., 247264., 214657., 260963.,\n",
       "       222350., 248046., 260513., 233065., 250641., 245209., 235223.,\n",
       "       207829., 204747., 247993., 196704., 249907., 238731., 258583.,\n",
       "       229959., 234411., 252637., 271701., 254323., 263385., 218289.,\n",
       "       274136., 257249., 233666., 244118., 238214., 240310., 241677.,\n",
       "       282627., 267635., 227756., 253441., 278579., 258736., 273820.,\n",
       "       286245., 261474., 247986., 263902., 241898., 239478., 239972.,\n",
       "       278268., 226631., 275647., 252997., 219014., 254353., 209999.,\n",
       "       273510., 255705., 236153., 242471., 281083., 234885., 218822.,\n",
       "       281633., 280252., 249074., 263229., 264830., 223150., 239294.,\n",
       "       270617., 296700., 263258., 242404., 278741., 236381., 235297.,\n",
       "       257847., 283083., 265080., 255297., 256266., 239870., 258163.,\n",
       "       188409., 241068., 253826., 220980., 243726., 245911., 275110.,\n",
       "       265460., 228684., 235983., 230521., 229967., 257900., 230834.,\n",
       "       219388., 258454., 256591., 229914., 255907., 225368., 239063.,\n",
       "       266407., 247328., 266095., 232671., 242071., 240883., 219068.,\n",
       "       232465., 220028., 230177., 240302., 237876., 242170., 254765.,\n",
       "       248589., 253490., 230005., 226936., 212159., 228256., 240962.,\n",
       "       241600., 221078., 228878., 246629., 253901., 229852., 235740.,\n",
       "       229466., 246371., 220031., 262463., 201283., 233807., 255022.,\n",
       "       255677., 294861., 251996., 223919., 240091., 216475., 249388.,\n",
       "       226339., 268308., 235009., 259665., 222289., 278777., 228575.,\n",
       "       273651., 266283., 251641., 251375., 258876., 210447., 234422.,\n",
       "       260903., 247022., 219896., 230952., 271082., 269938., 226760.,\n",
       "       268029., 225670., 207923., 223511., 279258., 232520., 243132.,\n",
       "       234003., 272083., 273519., 291376., 235819., 252912., 217667.,\n",
       "       280539., 223644., 256336., 214054., 245223., 225255., 231842.,\n",
       "       248218., 225035., 270667., 218903., 257411., 280359., 239736.,\n",
       "       238642., 246390., 261595., 232882., 225376., 261678., 222954.,\n",
       "       263627., 255172., 234844., 231228., 219266., 245696., 275580.,\n",
       "       233254., 256168., 200259., 234308., 249379., 231806., 243270.,\n",
       "       227644., 246844., 240253., 209235., 200586., 236863., 256154.,\n",
       "       196050., 237005., 237475., 274767., 238300., 256660., 242825.,\n",
       "       202389., 246364., 255308., 261165., 322525., 199318., 268494.,\n",
       "       241251., 253747., 247090., 227515., 241603., 252590., 207657.,\n",
       "       257012., 231676., 218399., 231000., 263143., 233293., 243169.,\n",
       "       235381., 259158., 264710., 283972., 246489., 274373., 232961.,\n",
       "       265917., 241623., 254900., 240106., 230716., 227835., 261045.,\n",
       "       243675., 246294., 289562., 262709., 257383., 228889., 226215.,\n",
       "       266106., 252521., 268453., 240920., 240409., 220210., 224151.,\n",
       "       265931., 234670., 265810., 240190., 254481., 209046., 253704.,\n",
       "       178177., 233262., 217391., 263120., 254548., 253333., 276420.,\n",
       "       216022., 286947., 257644., 236269., 268712., 228874., 239510.,\n",
       "       224828., 240420., 215869., 272462., 238823., 241050., 240593.,\n",
       "       227588., 253401., 215755., 235627., 218634., 288746., 251227.,\n",
       "       240115., 277274., 232074., 254870., 247996., 250280., 267447.,\n",
       "       263650., 240774., 203902., 224799., 245546., 243867., 225396.,\n",
       "       297234., 279328., 250042., 240441., 235756., 229962., 242550.,\n",
       "       259155., 226165., 246684., 244895., 196844., 226792., 237728.,\n",
       "       306754., 254131., 213290., 250721., 219054., 271654., 242578.,\n",
       "       252127., 275516., 208257., 213058., 229328., 270768., 224613.,\n",
       "       191357., 245977., 244035., 275005., 243737., 238771., 271078.,\n",
       "       216605., 237230., 244808., 259984., 244804., 247689., 197233.,\n",
       "       225835., 244070., 225354., 261180., 258937., 241149., 243409.,\n",
       "       224745., 232868., 257204., 250139., 227269., 243484., 249292.,\n",
       "       211001., 268181., 251275., 242510., 258945., 217567., 230811.,\n",
       "       234229., 227325., 290699., 229865., 240889., 252088., 215957.,\n",
       "       239086., 241349., 237343., 234132., 239413., 202711., 265432.,\n",
       "       284099., 247368., 251505., 263854., 229613., 280050., 245047.,\n",
       "       278637., 221339., 278361., 263503., 260061., 252680., 236029.,\n",
       "       268011., 258807., 201659., 219656., 245283., 248200., 242868.,\n",
       "       279379., 197978., 250872., 205640., 258194., 247111., 250392.,\n",
       "       231722., 270589., 263834., 248671., 247410., 252597., 221862.,\n",
       "       258111., 279990., 283412., 228408., 253228., 220137., 261448.,\n",
       "       253012., 202604., 207764., 240337., 240983., 219810., 252780.,\n",
       "       252029., 243115., 227884., 264974., 289108., 236329., 223757.,\n",
       "       245824., 232839., 256212., 259793., 208813., 267366., 251454.,\n",
       "       236770., 244215., 251249., 211376., 267899., 253827., 252860.,\n",
       "       266031., 228577., 258469., 235647., 268935., 206455., 239018.,\n",
       "       237944., 258645., 259401., 233847., 238757., 231787., 215067.,\n",
       "       259840., 234616., 186860., 225504., 230229., 197374., 218251.,\n",
       "       241188., 269573., 247264., 226870., 251118., 226818., 231108.,\n",
       "       223913., 197963., 231202., 255161., 244068., 228681., 221085.,\n",
       "       252165., 221657., 265521., 208956., 233951., 223664., 229972.,\n",
       "       260506., 252313., 272568., 254443., 211927., 238384., 232396.,\n",
       "       275611., 236064., 258874., 268859., 266592., 252806., 258246.,\n",
       "       284633., 229647., 220299., 201400., 258254., 201337.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sodas_sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{sodas_sold}_i = 200000 + 1000 * \\text{temp}_i + \\varepsilon_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with temp and sodas_sold.\n",
    "df = pd.DataFrame({'temp': temp,\n",
    "                   'sodas': sodas_sold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>sodas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>240170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>247757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>294087.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>242182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>251395.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp     sodas\n",
       "0    53  240170.0\n",
       "1    38  247757.0\n",
       "2    58  294087.0\n",
       "3    46  242182.0\n",
       "4    37  251395.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first five rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our goal is to fit a model here.\n",
    "- You and I know that our $y$-intercept $\\beta_0$ is 200,000.\n",
    "- You and I know that our slope $\\beta_1$ is 1,000.\n",
    "- However, our computer does not know that. Our computer has to estimate $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ from the data.\n",
    "    - We might say that our **machine** has to... **learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our workflow:\n",
    "1. Instantiate model.\n",
    "2. Select a learning rate $\\alpha$.\n",
    "3. Select a starting point $\\hat{\\beta}_{1,0}$.\n",
    "4. Calculate the gradient of the loss function.\n",
    "5. Calculate $\\hat{\\beta}_{1,i+1} = \\hat{\\beta}_{1,i} - \\alpha * \\frac{\\partial L}{\\partial \\beta_1}$.\n",
    "6. Check value of $\\left|\\hat{\\beta}_{1,i+1} - \\hat{\\beta}_{1,i}\\right|$.\n",
    "7. Repeat steps 4 through 6 until \"stopping condition\" is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Instantiate model.\n",
    "\n",
    "Our model takes on the form:\n",
    "$$ Y = \\beta_0 + \\beta_1 X + \\varepsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Select a learning rate $\\alpha$.\n",
    "\n",
    "$$\\alpha = 0.1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Select a starting point.\n",
    "The zero-th iteration of $\\hat{\\beta}_1$ is going to start at, say, 20.\n",
    "$$\\hat{\\beta}_{1,0} = 20$$\n",
    "\n",
    "Two points:\n",
    "- You and I know that the true value of $\\beta_1$ is 1000. We need the computer to figure (machine to learn) that part out!\n",
    "- We're going to pretend like the computer already knows the value for $\\beta_0$. In reality, we'd have to do this for $\\beta_0$ and for $\\beta_1$ at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Calculate the gradient of the loss function with respect to parameter $\\beta_1$.\n",
    "\n",
    "The loss function, $L$, is our mean square error.\n",
    "\n",
    "$$L = \\frac{1}{n}\\sum_{i = 1} ^ n (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "$$\\Rightarrow L = \\frac{1}{n}\\sum_{i = 1} ^ n \\left(y_i - \\left(\\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\right)\\right)^2 $$\n",
    "\n",
    "The gradient of this loss function with respect to $\\beta_1$ is:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\beta_1} = \\frac{2}{n} \\sum_{i=1}^n -x_i\\left(y_i - \\left(\\hat{\\beta}_1x_i + \\hat{\\beta}_0\\right)\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gradient of beta_1.\n",
    "def beta_1_gradient(x, y, beta_1, beta_0):\n",
    "    grad = -x * (y - (beta_1*x + beta_0))\n",
    "    return 2 * np.mean(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5. Calculate $\\hat{\\beta}_{1,i+1} = \\hat{\\beta}_{1,i} - \\alpha * \\frac{\\partial L}{\\partial \\beta_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate new value of beta_1.\n",
    "def update_beta_1(beta_1, alpha, gradient):\n",
    "    beta_1 = beta_1 - alpha * gradient\n",
    "    # alpha is step\n",
    "    return beta_1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6. Check value of $\\left|\\hat{\\beta}_{1,i+1} - \\hat{\\beta}_{1,i}\\right|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_update(beta_1, updated_beta_1, tolerance = 0.1):\n",
    "    return abs(beta_1 - updated_beta_1) < tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Save final value of $\\hat{\\beta}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, beta_1 = 0, alpha = 0.01, max_iter = 100):\n",
    "    # Set converged = False.\n",
    "    converged = False\n",
    "    \n",
    "    # Iterate through our observations.\n",
    "    step = 0\n",
    "    while not converged:\n",
    "        \n",
    "        # Calculate gradient.\n",
    "        gradient = beta_1_gradient(x, y, beta_1, 200000)\n",
    "        \n",
    "        # Update beta_1.\n",
    "        updated_beta_1 = update_beta_1(beta_1, alpha, gradient)\n",
    "        \n",
    "        # Check for convergence.\n",
    "        converged = check_update(beta_1, updated_beta_1)\n",
    "        \n",
    "        # Overwrite beta_1.\n",
    "        beta_1 = updated_beta_1\n",
    "        \n",
    "        # Print out current step findings.\n",
    "        print(f'Iteration {step} with beta_1 value of {beta_1}!')\n",
    "        \n",
    "        # If we've converged, let us know!\n",
    "        if converged:\n",
    "            print(f'Algorithm converged after {step} steps!')\n",
    "        else:\n",
    "            step += 1\n",
    "            \n",
    "        # If we exceed our step limit, break!\n",
    "        if step > max_iter:\n",
    "            break\n",
    "        \n",
    "    # If we didn't converge by the end of our loop, let us know!\n",
    "    if not converged:\n",
    "        print(\"Algorithm did not converge, cannot trust the value of beta_1.\")\n",
    "    \n",
    "    # Return beta_1.\n",
    "    return beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with beta_1 value of 40025.320660000005!\n",
      "Iteration 1 with beta_1 value of -1558308.0557753954!\n",
      "Iteration 2 with beta_1 value of 62299937.29961526!\n",
      "Iteration 3 with beta_1 value of -2489029816.549207!\n",
      "Iteration 4 with beta_1 value of 99444298865.56764!\n",
      "Iteration 5 with beta_1 value of -3973100020637.6216!\n",
      "Iteration 6 with beta_1 value of 158737344627359.4!\n",
      "Iteration 7 with beta_1 value of -6342036304602960.0!\n",
      "Iteration 8 with beta_1 value of 2.5338350331856915e+17!\n",
      "Iteration 9 with beta_1 value of -1.0123436175756835e+19!\n",
      "Iteration 10 with beta_1 value of 4.0446184799873643e+20!\n",
      "Iteration 11 with beta_1 value of -1.615947230233049e+22!\n",
      "Iteration 12 with beta_1 value of 6.456197200844529e+23!\n",
      "Iteration 13 with beta_1 value of -2.579445758892867e+25!\n",
      "Iteration 14 with beta_1 value of 1.0305664799396197e+27!\n",
      "Iteration 15 with beta_1 value of -4.117424318435715e+28!\n",
      "Iteration 16 with beta_1 value of 1.645035361429483e+30!\n",
      "Iteration 17 with beta_1 value of -6.572413069589948e+31!\n",
      "Iteration 18 with beta_1 value of 2.6258775081758816e+33!\n",
      "Iteration 19 with beta_1 value of -1.049117366017014e+35!\n",
      "Iteration 20 with beta_1 value of 4.191540710682498e+36!\n",
      "Iteration 21 with beta_1 value of -1.6746470984471227e+38!\n",
      "Iteration 22 with beta_1 value of 6.690720901719965e+39!\n",
      "Iteration 23 with beta_1 value of -2.6731450600083587e+41!\n",
      "Iteration 24 with beta_1 value of 1.0680021804541469e+43!\n",
      "Iteration 25 with beta_1 value of -4.266991247572814e+44!\n",
      "Iteration 26 with beta_1 value of 1.704791866541017e+46!\n",
      "Iteration 27 with beta_1 value of -6.811158353975037e+47!\n",
      "Iteration 28 with beta_1 value of 2.721263459395326e+49!\n",
      "Iteration 29 with beta_1 value of -1.0872269341849063e+51!\n",
      "Iteration 30 with beta_1 value of 4.3437999446028266e+52!\n",
      "Iteration 31 with beta_1 value of -1.7354792606271578e+54!\n",
      "Iteration 32 with beta_1 value of 6.933763760942217e+55!\n",
      "Iteration 33 with beta_1 value of -2.770248022161994e+57!\n",
      "Iteration 34 with beta_1 value of 1.1067977463439909e+59!\n",
      "Iteration 35 with beta_1 value of -4.421991249563643e+60!\n",
      "Iteration 36 with beta_1 value of 1.7667190483364035e+62!\n",
      "Iteration 37 with beta_1 value of -7.05857614725653e+63!\n",
      "Iteration 38 with beta_1 value of 2.820114339828615e+65!\n",
      "Iteration 39 with beta_1 value of -1.1267208462145933e+67!\n",
      "Iteration 40 with beta_1 value of 4.501590050322861e+68!\n",
      "Iteration 41 with beta_1 value of -1.7985211731235002e+70!\n",
      "Iteration 42 with beta_1 value of 7.185635240022654e+71!\n",
      "Iteration 43 with beta_1 value of -2.870878284573311e+73!\n",
      "Iteration 44 with beta_1 value of 1.1470025752112308e+75!\n",
      "Iteration 45 with beta_1 value of -4.582621682746602e+76!\n",
      "Iteration 46 with beta_1 value of 1.8308957574320825e+78!\n",
      "Iteration 47 with beta_1 value of -7.314981481459939e+79!\n",
      "Iteration 48 with beta_1 value of 2.922556014283975e+81!\n",
      "Iteration 49 with beta_1 value of -1.167649388898085e+83!\n",
      "Iteration 50 with beta_1 value of 4.665111938763283e+84!\n",
      "Iteration 51 with beta_1 value of -1.863853105916479e+86!\n",
      "Iteration 52 with beta_1 value of 7.446656041774371e+87!\n",
      "Iteration 53 with beta_1 value of -2.97516397770132e+89!\n",
      "Iteration 54 with beta_1 value of 1.1886678590438013e+91!\n",
      "Iteration 55 with beta_1 value of -4.749087074573399e+92!\n",
      "Iteration 56 with beta_1 value of 1.89740370872172e+94!\n",
      "Iteration 57 with beta_1 value of -7.580700832263306e+95!\n",
      "Iteration 58 with beta_1 value of 3.0287189196543317e+97!\n",
      "Iteration 59 with beta_1 value of -1.2100646757132802e+99!\n",
      "Iteration 60 with beta_1 value of 4.8345738190066434e+100!\n",
      "Iteration 61 with beta_1 value of -1.931558244822489e+102!\n",
      "Iteration 62 with beta_1 value of 7.71715851865576e+103!\n",
      "Iteration 63 with beta_1 value of -3.083237886390239e+105!\n",
      "Iteration 64 with beta_1 value of 1.2318466493970734e+107!\n",
      "Iteration 65 with beta_1 value of -4.921599382029445e+108!\n",
      "Iteration 66 with beta_1 value of 1.9663275854221005e+110!\n",
      "Iteration 67 with beta_1 value of -7.856072534692114e+111!\n",
      "Iteration 68 with beta_1 value of 3.138738231000052e+113!\n",
      "Iteration 69 with beta_1 value of -1.2540207131790948e+115!\n",
      "Iteration 70 with beta_1 value of 5.010191463405861e+116!\n",
      "Iteration 71 with beta_1 value of -2.0017227974128294e+118!\n",
      "Iteration 72 with beta_1 value of 7.997487095949104e+119!\n",
      "Iteration 73 with beta_1 value of -3.1952376189419725e+121!\n",
      "Iteration 74 with beta_1 value of 1.2765939249434095e+123!\n",
      "Iteration 75 with beta_1 value of -5.100378261514247e+124!\n",
      "Iteration 76 with beta_1 value of 2.0377551468984347e+126!\n",
      "Iteration 77 with beta_1 value of -8.141447213913624e+127!\n",
      "Iteration 78 with beta_1 value of 3.252754033664364e+129!\n",
      "Iteration 79 with beta_1 value of -1.2995734696207302e+131!\n",
      "Iteration 80 with beta_1 value of 5.1921884823226534e+132!\n",
      "Iteration 81 with beta_1 value of -2.0744361027800643e+134!\n",
      "Iteration 82 with beta_1 value of 8.287998710309394e+135!\n",
      "Iteration 83 with beta_1 value of -3.31130578232965e+137!\n",
      "Iteration 84 with beta_1 value of 1.3229666614753288e+139!\n",
      "Iteration 85 with beta_1 value of -5.285651348525696e+140!\n",
      "Iteration 86 with beta_1 value of 2.1117773404067398e+142!\n",
      "Iteration 87 with beta_1 value of -8.437188231681734e+143!\n",
      "Iteration 88 with beta_1 value of 3.3709115016414444e+145!\n",
      "Iteration 89 with beta_1 value of -1.34678094643311e+147!\n",
      "Iteration 90 with beta_1 value of 5.380796608846095e+148!\n",
      "Iteration 91 with beta_1 value of -2.149790745291608e+150!\n",
      "Iteration 92 with beta_1 value of 8.589063264245051e+151!\n",
      "Iteration 93 with beta_1 value of -3.431590163776478e+153!\n",
      "Iteration 94 with beta_1 value of 1.371023904451648e+155!\n",
      "Iteration 95 with beta_1 value of -5.477654547503467e+156!\n",
      "Iteration 96 with beta_1 value of 2.188488416894981e+158!\n",
      "Iteration 97 with beta_1 value of -8.74367214899735e+159!\n",
      "Iteration 98 with beta_1 value of 3.493361082423359e+161!\n",
      "Iteration 99 with beta_1 value of -1.3957032519328118e+163!\n",
      "Iteration 100 with beta_1 value of 5.576255993853665e+164!\n",
      "Algorithm did not converge, cannot trust the value of beta_1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.576255993853665e+164"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call gradient_descent with an initial beta_1 of 20, alpha of 0.01, and 100 iterations.\n",
    "# For this, step size is too big, \n",
    "# that's why the value keeps getting larger in magnitude\n",
    "# This is Problem 2 in the slides\n",
    "# Solution: smaller step size.\n",
    "\n",
    "gradient_descent(\n",
    "    df['temp'],\n",
    "    df['sodas'],\n",
    "    beta_1=20,\n",
    "    alpha=0.01,\n",
    "    max_iter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with beta_1 value of 60.00532066!\n",
      "Iteration 1 with beta_1 value of 98.37230262290458!\n",
      "Iteration 2 with beta_1 value of 135.1680408061427!\n",
      "Iteration 3 with beta_1 value of 170.45688238764797!\n",
      "Iteration 4 with beta_1 value of 204.30053933408902!\n",
      "Iteration 5 with beta_1 value of 236.7581963207292!\n",
      "Iteration 6 with beta_1 value of 267.8866142316425!\n",
      "Iteration 7 with beta_1 value of 297.74022942128187!\n",
      "Iteration 8 with beta_1 value of 326.37124891098756!\n",
      "Iteration 9 with beta_1 value of 353.82974168691084!\n",
      "Iteration 10 with beta_1 value of 380.163726259012!\n",
      "Iteration 11 with beta_1 value of 405.41925463425224!\n",
      "Iteration 12 with beta_1 value of 429.6404928508307!\n",
      "Iteration 13 with beta_1 value of 452.8697982143008!\n",
      "Iteration 14 with beta_1 value of 475.1477933706346!\n",
      "Iteration 15 with beta_1 value of 496.513437345771!\n",
      "Iteration 16 with beta_1 value of 517.0040936758809!\n",
      "Iteration 17 with beta_1 value of 536.6555957474906!\n",
      "Iteration 18 with beta_1 value of 555.5023094617317!\n",
      "Iteration 19 with beta_1 value of 573.5771933322992!\n",
      "Iteration 20 with beta_1 value of 590.9118561222176!\n",
      "Iteration 21 with beta_1 value of 607.5366121202073!\n",
      "Iteration 22 with beta_1 value of 623.4805341533163!\n",
      "Iteration 23 with beta_1 value of 638.7715044285248!\n",
      "Iteration 24 with beta_1 value of 653.4362632922333!\n",
      "Iteration 25 with beta_1 value of 667.5004559929013!\n",
      "Iteration 26 with beta_1 value of 680.9886775286149!\n",
      "Iteration 27 with beta_1 value of 693.9245156580118!\n",
      "Iteration 28 with beta_1 value of 706.3305921497789!\n",
      "Iteration 29 with beta_1 value of 718.2286023428571!\n",
      "Iteration 30 with beta_1 value of 729.639353086538!\n",
      "Iteration 31 with beta_1 value of 740.582799126798!\n",
      "Iteration 32 with beta_1 value of 751.0780780025023!\n",
      "Iteration 33 with beta_1 value of 761.1435435125042!\n",
      "Iteration 34 with beta_1 value of 770.7967978121657!\n",
      "Iteration 35 with beta_1 value of 780.0547221954281!\n",
      "Iteration 36 with beta_1 value of 788.9335066162643!\n",
      "Iteration 37 with beta_1 value of 797.4486780011383!\n",
      "Iteration 38 with beta_1 value of 805.6151274019841!\n",
      "Iteration 39 with beta_1 value of 813.447136037188!\n",
      "Iteration 40 with beta_1 value of 820.9584002661143!\n",
      "Iteration 41 with beta_1 value of 828.1620555408481!\n",
      "Iteration 42 with beta_1 value of 835.0706993770426!\n",
      "Iteration 43 with beta_1 value of 841.6964133840406!\n",
      "Iteration 44 with beta_1 value of 848.0507843927958!\n",
      "Iteration 45 with beta_1 value of 854.1449247185419!\n",
      "Iteration 46 with beta_1 value of 859.989491593645!\n",
      "Iteration 47 with beta_1 value of 865.5947058046206!\n",
      "Iteration 48 with beta_1 value of 870.9703695659099!\n",
      "Iteration 49 with beta_1 value of 876.1258836616698!\n",
      "Iteration 50 with beta_1 value of 881.0702638855557!\n",
      "Iteration 51 with beta_1 value of 885.8121568072453!\n",
      "Iteration 52 with beta_1 value of 890.359854893275!\n",
      "Iteration 53 with beta_1 value of 894.7213110086336!\n",
      "Iteration 54 with beta_1 value of 898.9041523244708!\n",
      "Iteration 55 with beta_1 value of 902.9156936562438!\n",
      "Iteration 56 with beta_1 value of 906.7629502556257!\n",
      "Iteration 57 with beta_1 value of 910.4526500785481!\n",
      "Iteration 58 with beta_1 value of 913.9912455508284!\n",
      "Iteration 59 with beta_1 value of 917.3849248519604!\n",
      "Iteration 60 with beta_1 value of 920.6396227367995!\n",
      "Iteration 61 with beta_1 value of 923.761030914067!\n",
      "Iteration 62 with beta_1 value of 926.7546079998226!\n",
      "Iteration 63 with beta_1 value of 929.6255890633137!\n",
      "Iteration 64 with beta_1 value of 932.378994781892!\n",
      "Iteration 65 with beta_1 value of 935.0196402210092!\n",
      "Iteration 66 with beta_1 value of 937.5521432546454!\n",
      "Iteration 67 with beta_1 value of 939.980932640895!\n",
      "Iteration 68 with beta_1 value of 942.3102557668338!\n",
      "Iteration 69 with beta_1 value of 944.5441860762096!\n",
      "Iteration 70 with beta_1 value of 946.6866301929468!\n",
      "Iteration 71 with beta_1 value of 948.7413347529225!\n",
      "Iteration 72 with beta_1 value of 950.7118929559593!\n",
      "Iteration 73 with beta_1 value of 952.601750849496!\n",
      "Iteration 74 with beta_1 value of 954.4142133549216!\n",
      "Iteration 75 with beta_1 value of 956.1524500471132!\n",
      "Iteration 76 with beta_1 value of 957.8195006972848!\n",
      "Iteration 77 with beta_1 value of 959.4182805888388!\n",
      "Iteration 78 with beta_1 value of 960.9515856155184!\n",
      "Iteration 79 with beta_1 value of 962.4220971707744!\n",
      "Iteration 80 with beta_1 value of 963.8323868368977!\n",
      "Iteration 81 with beta_1 value of 965.1849208821185!\n",
      "Iteration 82 with beta_1 value of 966.4820645735347!\n",
      "Iteration 83 with beta_1 value of 967.7260863134134!\n",
      "Iteration 84 with beta_1 value of 968.9191616060984!\n",
      "Iteration 85 with beta_1 value of 970.0633768624607!\n",
      "Iteration 86 with beta_1 value of 971.1607330485448!\n",
      "Iteration 87 with beta_1 value of 972.2131491847931!\n",
      "Iteration 88 with beta_1 value of 973.2224657019653!\n",
      "Iteration 89 with beta_1 value of 974.1904476596235!\n",
      "Iteration 90 with beta_1 value of 975.11878783281!\n",
      "Iteration 91 with beta_1 value of 976.0091096723171!\n",
      "Iteration 92 with beta_1 value of 976.8629701437245!\n",
      "Iteration 93 with beta_1 value of 977.6818624501692!\n",
      "Iteration 94 with beta_1 value of 978.4672186436102!\n",
      "Iteration 95 with beta_1 value of 979.220412129154!\n",
      "Iteration 96 with beta_1 value of 979.9427600668206!\n",
      "Iteration 97 with beta_1 value of 980.6355256749489!\n",
      "Iteration 98 with beta_1 value of 981.2999204392722!\n",
      "Iteration 99 with beta_1 value of 981.9371062315244!\n",
      "Iteration 100 with beta_1 value of 982.5481973412826!\n",
      "Algorithm did not converge, cannot trust the value of beta_1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "982.5481973412826"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step size too small, that's why it did not converge\n",
    "gradient_descent(\n",
    "    df['temp'],\n",
    "    df['sodas'],\n",
    "    beta_1=20,\n",
    "    alpha=0.00001,\n",
    "    max_iter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with beta_1 value of 420.0532066!\n",
      "Iteration 1 with beta_1 value of 656.2725434904612!\n",
      "Iteration 2 with beta_1 value of 795.7529281003042!\n",
      "Iteration 3 with beta_1 value of 878.1118829048013!\n",
      "Iteration 4 with beta_1 value of 926.7423584764215!\n",
      "Iteration 5 with beta_1 value of 955.457185661101!\n",
      "Iteration 6 with beta_1 value of 972.4124239258731!\n",
      "Iteration 7 with beta_1 value of 982.4239800730255!\n",
      "Iteration 8 with beta_1 value of 988.3355016289233!\n",
      "Iteration 9 with beta_1 value of 991.82607657973!\n",
      "Iteration 10 with beta_1 value of 993.8871556728179!\n",
      "Iteration 11 with beta_1 value of 995.1041606326977!\n",
      "Iteration 12 with beta_1 value of 995.8227653079568!\n",
      "Iteration 13 with beta_1 value of 996.2470796668362!\n",
      "Iteration 14 with beta_1 value of 996.4976244814608!\n",
      "Iteration 15 with beta_1 value of 996.6455636280433!\n",
      "Iteration 16 with beta_1 value of 996.732917226338!\n",
      "Algorithm converged after 16 steps!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "996.732917226338"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one is ok\n",
    "gradient_descent(\n",
    "    df['temp'],\n",
    "    df['sodas'],\n",
    "    beta_1=20,\n",
    "    alpha=0.0001,\n",
    "    max_iter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What should we do?</summary>\n",
    "\n",
    "- We **should not** adjust our maximum iterations. It doesn't look like we'll converge.\n",
    "- We should adjust our alpha!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 1. Change Step Size (alpha)\n",
    "## More difficult to gauge if it's Problem 2 (step too big) or Problem 3 (step too small)\n",
    "\n",
    "# 2. Increase iterations (max_iter)\n",
    "## But if still too big step size, it will keep increasing\n",
    "## If step size too small, might be ok \n",
    "\n",
    "## Cannot use constant step size for neural networks\n",
    "## Need to make sure you hit the global minimum cause there's a lot of local minimums"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
