{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a37b1d",
   "metadata": {},
   "source": [
    "> Q1: Predict weight as function of height and gender using lin reg. You want to add interaction term on math and gender. Interpret\n",
    "\n",
    "a\n",
    "\n",
    "> Q2 H, G + avg weekly caloric intake. Variables are enough, so use preprocessor. \n",
    "\n",
    "Part A: What's the default degree in Poly?\n",
    "\n",
    "Degree = 2\n",
    "\n",
    "Part B: What are the features that will result?\n",
    "\n",
    "H2, HG, HC, G2, GC, C2\n",
    "\n",
    "Part C: What are 3 features you get as a result of PolyFeatures?\n",
    "\n",
    "1. fit\n",
    "2. alpha\n",
    "3. feature names?\n",
    "\n",
    "1. Square term\n",
    "2. Original term.\n",
    "3. R2\n",
    "\n",
    "> Q3: As a result of Poly Features, you get several columns but 2 of these columns will be exactly the same. Which two are these?\n",
    "\n",
    "1. Gender and Gender2\n",
    "\n",
    "> Q4: Why do we not, say, set degree = 4? What problems could arise?\n",
    "\n",
    "1. Multicolinearity.\n",
    "\n",
    "2. Overfitting. Too many variables.\n",
    "\n",
    "> Q5. 3 types of regularization. What are the penalty terms?\n",
    "\n",
    "1. L1 Regularization ==> Lasso ==> a1. This is the one that we use absolute values. The diamond shape one that will get to zero.\n",
    "\n",
    "2. L2 Regularization ==> Ridge ==> a2. This is the one we square to get positive numbers. The circle which will get close to but not reach zero.\n",
    "\n",
    "3. Elastic Net Regularization ==> Both Lasso and Ridge ==> a1 and a2. Combination of bot a1 and a2 depending on what L1 is. L1=0 ==> Lasso, L1=1 ==> Ridge\n",
    "\n",
    "> Q6. Why is regularization aka Penalization or Shrinkage?\n",
    "\n",
    "1. Penalization: It penalizes the X variables that do not hold much weight to the fitting of the model and this will result in higher a.\n",
    "\n",
    "==> Causee you add a penalty term. If beta is big, MSE will also be big\n",
    "\n",
    "2. Shrinkage: Because we want to shrink a such that we will end up shrinking the # of variables too.\n",
    "\n",
    "> Q7. T/F: Ridge sets coeffs to 0 such that we can use it to decide which variables to drop.\n",
    "\n",
    "False. Ridge values can get close to but not reach 0.\n",
    "\n",
    "> Q8. 2 greek letters are used interchangeably for penalization. Which are they? Which does sklearn use?\n",
    "\n",
    "Lambda and Alpha.\n",
    "sklearn uses alpha\n",
    "\n",
    "> Q9. As this penalization term becomes big, what happens to the coeffs inside regression? What if this term = 0?\n",
    "\n",
    "Coeffs (Betas) become smaller.\n",
    "If term = 0, we get lin reg.\n",
    "\n",
    "> Q10. How many parameters will there be if we fit height and gender (X) into weight (Y)? How many hyperparameters?\n",
    "\n",
    "Parameters: Height, Gender, Coeffs.\n",
    "Hyperparameters: Alpha and L1 ratio\n",
    "\n",
    "> Q11. How, in general, are the hyperparameters set? When do you get to set the hyperparameters using sklearn library?\n",
    "\n",
    "Parameters are set at point of instantiation.\n",
    "Ridge_alpha = 0\n",
    "\n",
    "> Q12. How, in general, are the hyperparameters selected?\n",
    "\n",
    "Cross validation. Estimate of error on unseen data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e618bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13.\n",
    "ss = StandardScaler()\n",
    "ss.fit.(X_train)\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "ss.fit.(X_test) # --> You don't fit TEST!!!!! Data leak\n",
    "X_test_scaled = ss.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac391f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08580b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f98c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e13c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396500b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914dae1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
