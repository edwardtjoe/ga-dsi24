{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practice Spark Lab\n",
    "\n",
    "*Authors: Christoph Rahmede (LDN)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this lab, we will use Spark to dig into the Bay Area Bike Share data.**\n",
    "\n",
    "Our goal is to calculate the average number of trips per hour, using the Caltrain Station as starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = ps.SparkContext('local[4]')\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = ps.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = spark.read.csv(\n",
    "    path=\"./data/201508_trip_data.csv\",\n",
    "    header=True,\n",
    "    # Poorly formed rows in CSV are dropped rather than erroring entire operation\n",
    "    mode=\"DROPMALFORMED\",\n",
    "    # Not always perfect but works well in most cases as of 2.1+\n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.registerTempTable(\"tripsSql_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
      "|Trip ID|Duration|     Start Date|       Start Station|Start Terminal|       End Date|         End Station|End Terminal|Bike #|Subscriber Type|Zip Code|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
      "| 913460|     765|8/31/2015 23:26|Harry Bridges Pla...|            50|8/31/2015 23:39|San Francisco Cal...|          70|   288|     Subscriber|    2139|\n",
      "| 913459|    1036|8/31/2015 23:11|San Antonio Shopp...|            31|8/31/2015 23:28|Mountain View Cit...|          27|    35|     Subscriber|   95032|\n",
      "| 913455|     307|8/31/2015 23:13|      Post at Kearny|            47|8/31/2015 23:18|   2nd at South Park|          64|   468|     Subscriber|   94107|\n",
      "| 913454|     409|8/31/2015 23:10|  San Jose City Hall|            10|8/31/2015 23:17| San Salvador at 1st|           8|    68|     Subscriber|   95113|\n",
      "| 913453|     789|8/31/2015 23:09|Embarcadero at Fo...|            51|8/31/2015 23:22|Embarcadero at Sa...|          60|   487|       Customer|    9069|\n",
      "| 913452|     293|8/31/2015 23:07|Yerba Buena Cente...|            68|8/31/2015 23:12|San Francisco Cal...|          70|   538|     Subscriber|   94118|\n",
      "| 913451|     896|8/31/2015 23:07|Embarcadero at Fo...|            51|8/31/2015 23:22|Embarcadero at Sa...|          60|   363|       Customer|   92562|\n",
      "| 913450|     255|8/31/2015 22:16|Embarcadero at Sa...|            60|8/31/2015 22:20|   Steuart at Market|          74|   470|     Subscriber|   94111|\n",
      "| 913449|     126|8/31/2015 22:12|     Beale at Market|            56|8/31/2015 22:15|Temporary Transba...|          55|   439|     Subscriber|   94130|\n",
      "| 913448|     932|8/31/2015 21:57|      Post at Kearny|            47|8/31/2015 22:12|South Van Ness at...|          66|   472|     Subscriber|   94702|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamps\n",
    "\n",
    "You can use the following functions to cast into a timestamp and to extract parts of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, to_date, to_timestamp, year, month, dayofweek, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trips.withColumn('time', to_timestamp('Start Date', format='MM/dd/yyyy HH:mm'))\n",
    "df = df.withColumn('hour', hour('time'))\n",
    "df = df.withColumn('day', to_date('time'))\n",
    "df = df.withColumn('month', month('time'))\n",
    "df = df.withColumn('weekday', dayofweek('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+----+----------+-----+-------+\n",
      "|     Start Date|               time|hour|       day|month|weekday|\n",
      "+---------------+-------------------+----+----------+-----+-------+\n",
      "|8/31/2015 23:26|2015-08-31 23:26:00|  23|2015-08-31|    8|      2|\n",
      "|8/31/2015 23:11|2015-08-31 23:11:00|  23|2015-08-31|    8|      2|\n",
      "|8/31/2015 23:13|2015-08-31 23:13:00|  23|2015-08-31|    8|      2|\n",
      "|8/31/2015 23:10|2015-08-31 23:10:00|  23|2015-08-31|    8|      2|\n",
      "|8/31/2015 23:09|2015-08-31 23:09:00|  23|2015-08-31|    8|      2|\n",
      "|8/31/2015 23:07|2015-08-31 23:07:00|  23|2015-08-31|    8|      2|\n",
      "|8/31/2015 23:07|2015-08-31 23:07:00|  23|2015-08-31|    8|      2|\n",
      "|8/31/2015 22:16|2015-08-31 22:16:00|  22|2015-08-31|    8|      2|\n",
      "|8/31/2015 22:12|2015-08-31 22:12:00|  22|2015-08-31|    8|      2|\n",
      "|8/31/2015 21:57|2015-08-31 21:57:00|  21|2015-08-31|    8|      2|\n",
      "+---------------+-------------------+----+----------+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Start Date', 'time', 'hour', 'day', 'month', 'weekday').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our datetime parsing has not been perfect. We can check for missing values. We should really try to cure this. Here let's just drop the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip ID</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Start Station</th>\n",
       "      <th>Start Terminal</th>\n",
       "      <th>End Date</th>\n",
       "      <th>End Station</th>\n",
       "      <th>End Terminal</th>\n",
       "      <th>Bike #</th>\n",
       "      <th>Subscriber Type</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702587</td>\n",
       "      <td>699</td>\n",
       "      <td>3/29/2015 1:43</td>\n",
       "      <td>San Jose Diridon Caltrain Station</td>\n",
       "      <td>2</td>\n",
       "      <td>3/29/2015 1:55</td>\n",
       "      <td>Japantown</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>95112</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702585</td>\n",
       "      <td>226</td>\n",
       "      <td>3/29/2015 1:30</td>\n",
       "      <td>Grant Avenue at Columbus Avenue</td>\n",
       "      <td>73</td>\n",
       "      <td>3/29/2015 1:34</td>\n",
       "      <td>Broadway St at Battery St</td>\n",
       "      <td>82</td>\n",
       "      <td>563</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>94114</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip ID  Duration      Start Date                      Start Station  \\\n",
       "0   702587       699  3/29/2015 1:43  San Jose Diridon Caltrain Station   \n",
       "1   702585       226  3/29/2015 1:30    Grant Avenue at Columbus Avenue   \n",
       "\n",
       "   Start Terminal        End Date                End Station  End Terminal  \\\n",
       "0               2  3/29/2015 1:55                  Japantown             9   \n",
       "1              73  3/29/2015 1:34  Broadway St at Battery St            82   \n",
       "\n",
       "   Bike # Subscriber Type Zip Code time  hour   day  month  weekday  \n",
       "0      79      Subscriber    95112  NaT   NaN  None    NaN      NaN  \n",
       "1     563      Subscriber    94114  NaT   NaN  None    NaN      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.where(col('day').isNull()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a temporary SQL table from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following exercises, where possible use both dataframe methods and SQL queries\n",
    "\n",
    "Hint: In Hive SQL, you can refer to column names including spaces with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT `column name` FROM table\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mean, standard deviation, minimum and maximum of the duration column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For how many different days do you have observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the first and last observed days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the counts of rides per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the counts per hour averaged over all observed dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the average duration of trips per hour departing from terminal 70 sorted by the hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
