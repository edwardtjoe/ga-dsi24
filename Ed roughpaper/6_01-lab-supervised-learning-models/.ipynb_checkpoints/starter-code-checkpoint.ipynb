{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier, \n",
    "    BaggingClassifier, \n",
    "    RandomForestClassifier,\n",
    "    BaggingRegressor, \n",
    "    RandomForestRegressor, \n",
    "    AdaBoostRegressor)\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9275, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0\n",
       "inc       0\n",
       "marr      0\n",
       "male      0\n",
       "age       0\n",
       "fsize     0\n",
       "nettfa    0\n",
       "p401k     0\n",
       "pira      0\n",
       "incsq     0\n",
       "agesq     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ans: \n",
    "1. Amount of savings/investments\n",
    "2. Property ownership: Own or lease\n",
    "3. Credit score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This may be unethical because of discrimination against certain races."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Income and Income^2.\n",
    "This is what we are trying to predict. Income^2 is a feature engineered based on income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Income^2 and Age^2.\n",
    "\n",
    "Marginal differences income and age may have a disproportional effect on 401k contributions. For instance, keeping expenses equal, someone with higher income are more able to increase their 401k contributions since they spend a smaller proportion on expenses.\n",
    "\n",
    "Why squared: SME quadratic r/s betw inc and age squared\n",
    "\n",
    "Similarly, those with higher age may place a disproportionately larger focus on increasing their retirement contributions as compared to those with lower age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "inc\n",
    "Current description is income^2\n",
    "Correct description is income\n",
    "\n",
    "age\n",
    "Current description: age^2\n",
    "Correct description: age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Target: Income\n",
    "\n",
    "1. Linear Regression            --> Appropriate since our target is a continuous variable\n",
    "2. Logistic Regression          --> Not appropriate since our target is not binary. ===> DO NOT INCLUDE!!!!!!!!!!\n",
    "3. DecisionTree, RF, Bagging    --> Appropriate since we are able to see the effect of our features (columns).\n",
    "4. KNN                          --> Not appropriate since it not parametric.\n",
    "5. ADA                          --> Appropriate since we can identify the effect of features similar to DTree n Co\n",
    "\n",
    "Ans:\n",
    "1. State Reg models\n",
    "2. Key differences betw them\n",
    "3. Understand/interpret key features (coefs)\n",
    "\n",
    "Not parametric: Cannot form equation mx+c \n",
    "\n",
    "Ensemble models can be used to find feature importances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['inc', 'incsq', 'e401k', 'p401k', 'pira'])\n",
    "y = df['inc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('lr', LinearRegression())]),\n",
       "             param_grid={'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Linreg\n",
    "\n",
    "lr = LinearRegression()\n",
    "ss = StandardScaler()\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "pipe_lr_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False]\n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=pipe_lr_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('knn', KNeighborsRegressor())]),\n",
       "             param_grid={'knn__metric': ['euclidean', 'minkowski', 'manhattan'],\n",
       "                         'knn__n_neighbors': [5, 7, 9, 11],\n",
       "                         'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. KNN Reg\n",
    "\n",
    "ss = StandardScaler()\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "pipe_knn_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    'knn__n_neighbors': [5, 7, 9, 11],\n",
    "#     'knn__n_jobs': [-1],\n",
    "    'knn__metric': ['euclidean', 'minkowski', 'manhattan']\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    estimator=pipe_knn,\n",
    "    param_grid=pipe_knn_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('knn', KNeighborsClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'knn': KNeighborsClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('tree', DecisionTreeRegressor())]),\n",
       "             param_grid={'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False],\n",
       "                         'tree__max_depth': [None, 1, 3, 5],\n",
       "                         'tree__max_features': [None, 1, 3, 5],\n",
       "                         'tree__random_state': [42]})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. DTree Reg\n",
    "ss = StandardScaler()\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "pipe_tree = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('tree', tree)\n",
    "])\n",
    "\n",
    "pipe_tree_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    'tree__max_depth': [None, 1, 3, 5],\n",
    "    'tree__max_features': [None, 1, 3, 5],\n",
    "    'tree__random_state': [42],\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    estimator=pipe_tree,\n",
    "    param_grid=pipe_tree_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('tree', DecisionTreeClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'tree': DecisionTreeClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'tree__ccp_alpha': 0.0,\n",
       " 'tree__class_weight': None,\n",
       " 'tree__criterion': 'gini',\n",
       " 'tree__max_depth': None,\n",
       " 'tree__max_features': None,\n",
       " 'tree__max_leaf_nodes': None,\n",
       " 'tree__min_impurity_decrease': 0.0,\n",
       " 'tree__min_impurity_split': None,\n",
       " 'tree__min_samples_leaf': 1,\n",
       " 'tree__min_samples_split': 2,\n",
       " 'tree__min_weight_fraction_leaf': 0.0,\n",
       " 'tree__random_state': None,\n",
       " 'tree__splitter': 'best'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('bag', BaggingRegressor())]),\n",
       "             param_grid={'bag__max_features': [1, 3, 5],\n",
       "                         'bag__max_samples': [0.5, 0.75, 1.0],\n",
       "                         'bag__n_estimators': [3, 5, 10], 'bag__n_jobs': [-1],\n",
       "                         'bag__random_state': [42],\n",
       "                         'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Bagging Reg\n",
    "ss = StandardScaler()\n",
    "bag = BaggingRegressor()\n",
    "\n",
    "pipe_bag = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('bag', bag)\n",
    "])\n",
    "\n",
    "pipe_bag_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    'bag__n_estimators': [3, 5, 10],\n",
    "    'bag__max_features': [1, 3, 5],\n",
    "    'bag__max_samples': [0.5, 0.75, 1.0],\n",
    "    'bag__random_state': [42],\n",
    "    'bag__n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gs_bag = GridSearchCV(\n",
    "    estimator=pipe_bag,\n",
    "    param_grid=pipe_bag_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('bag', BaggingRegressor())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'bag': BaggingRegressor(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'bag__base_estimator': None,\n",
       " 'bag__bootstrap': True,\n",
       " 'bag__bootstrap_features': False,\n",
       " 'bag__max_features': 1.0,\n",
       " 'bag__max_samples': 1.0,\n",
       " 'bag__n_estimators': 10,\n",
       " 'bag__n_jobs': None,\n",
       " 'bag__oob_score': False,\n",
       " 'bag__random_state': None,\n",
       " 'bag__verbose': 0,\n",
       " 'bag__warm_start': False}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_bag.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('rf', RandomForestRegressor())]),\n",
       "             param_grid={'rf__max_depth': [None, 2, 4, 6],\n",
       "                         'rf__max_features': [None, 4, 6],\n",
       "                         'rf__n_estimators': [50, 75, 100],\n",
       "                         'rf__n_jobs': [2, 4], 'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Random Forest Reg\n",
    "ss = StandardScaler()\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "pipe_rf_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    'rf__max_depth': [None, 2, 4, 6],\n",
    "    'rf__n_jobs': [2, 4],\n",
    "    'rf__n_estimators': [50, 75, 100],\n",
    "    'rf__max_features': [None, 4, 6],\n",
    "}\n",
    "\n",
    "gs_pipe = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=pipe_rf_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('rf', RandomForestRegressor())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'rf': RandomForestRegressor(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'rf__bootstrap': True,\n",
       " 'rf__ccp_alpha': 0.0,\n",
       " 'rf__criterion': 'mse',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__max_leaf_nodes': None,\n",
       " 'rf__max_samples': None,\n",
       " 'rf__min_impurity_decrease': 0.0,\n",
       " 'rf__min_impurity_split': None,\n",
       " 'rf__min_samples_leaf': 1,\n",
       " 'rf__min_samples_split': 2,\n",
       " 'rf__min_weight_fraction_leaf': 0.0,\n",
       " 'rf__n_estimators': 100,\n",
       " 'rf__n_jobs': None,\n",
       " 'rf__oob_score': False,\n",
       " 'rf__random_state': None,\n",
       " 'rf__verbose': 0,\n",
       " 'rf__warm_start': False}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('ada', AdaBoostRegressor())]),\n",
       "             param_grid={'ada__n_estimators': [50, 100],\n",
       "                         'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. ADA Boost Reg\n",
    "ss = StandardScaler()\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "pipe_ada = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('ada', ada)\n",
    "])\n",
    "\n",
    "pipe_ada_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    'ada__n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "gs_ada = GridSearchCV(\n",
    "    estimator=pipe_ada,\n",
    "    param_grid=pipe_ada_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('ada', AdaBoostRegressor())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'ada': AdaBoostRegressor(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'ada__base_estimator': None,\n",
       " 'ada__learning_rate': 1.0,\n",
       " 'ada__loss': 'linear',\n",
       " 'ada__n_estimators': 50,\n",
       " 'ada__random_state': None}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ada.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bootstrapping is a method of taking samples with replace=True. Using DecisionTree as a base estimator, it votes on the best model based on the aggregated voting of the total number of trees created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In a decision tree, only one tree is made\n",
    "In bagging, multiple trees are made and then the final tree is made based on the voting of the multiple trees created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random forests use a subset of randomly chosen features (random column chosen). ==> Key: Random subset of features\n",
    "Bagged dtrees use all features and randomly chooses samples (random row chosen). \n",
    "\n",
    "Bag dtree: Every variable is a candidate. Features chosen based on Gini impurity, thus it is not randomly chosen.\n",
    "\n",
    "Extra trees: Split is randomly chosen (variable). Split not chosen by Gini (need to confirm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bagged decision trees uses all the variables present whereas random forest selects a subset of variables. As such, bagged decision trees have much greater overfitting (variance) as compared to random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinReg R^2 Train:   0.293\n",
      "LinReg R^2 Test:    0.275\n",
      "LinReg RMSE Train:  20.164\n",
      "LinReg RMSE Test:   20.897\n",
      "LinReg Best Params: {'ss__with_mean': False, 'ss__with_std': False}\n"
     ]
    }
   ],
   "source": [
    "print(f'LinReg R^2 Train:   {round(gs_lr.score(X_train, y_train),3)}')\n",
    "print(f'LinReg R^2 Test:    {round(gs_lr.score(X_test, y_test),3)}')\n",
    "print(f'LinReg RMSE Train:  {round((metrics.mean_squared_error(y_train, gs_lr.predict(X_train))**0.5),3)}')\n",
    "print(f'LinReg RMSE Test:   {round((metrics.mean_squared_error(y_test, gs_lr.predict(X_test))**0.5),3)}')\n",
    "print(f'LinReg Best Params: {gs_lr.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN R^2 Train:   0.447\n",
      "KNN R^2 Test:    0.367\n",
      "KNN RMSE Train:  17.833\n",
      "KNN RMSE Test:   19.531\n",
      "KNN Best Params: {'knn__metric': 'euclidean', 'knn__n_neighbors': 11, 'ss__with_mean': True, 'ss__with_std': True}\n"
     ]
    }
   ],
   "source": [
    "print(f'KNN R^2 Train:   {round(gs_knn.score(X_train, y_train),3)}')\n",
    "print(f'KNN R^2 Test:    {round(gs_knn.score(X_test, y_test),3)}')\n",
    "print(f'KNN RMSE Train:  {round((metrics.mean_squared_error(y_train, gs_knn.predict(X_train))**0.5),3)}')\n",
    "print(f'KNN RMSE Test:   {round((metrics.mean_squared_error(y_test, gs_knn.predict(X_test))**0.5),3)}')\n",
    "print(f'KNN Best Params: {gs_knn.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree R^2 Train:   0.419\n",
      "Tree R^2 Test:    0.382\n",
      "Tree RMSE Train:  18.274\n",
      "Tree RMSE Test:   19.298\n",
      "Tree Best Params: {'ss__with_mean': True, 'ss__with_std': True, 'tree__max_depth': 5, 'tree__max_features': None, 'tree__random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "print(f'Tree R^2 Train:   {round(gs_tree.score(X_train, y_train),3)}')\n",
    "print(f'Tree R^2 Test:    {round(gs_tree.score(X_test, y_test),3)}')\n",
    "print(f'Tree RMSE Train:  {round((metrics.mean_squared_error(y_train, gs_tree.predict(X_train))**0.5),3)}')\n",
    "print(f'Tree RMSE Test:   {round((metrics.mean_squared_error(y_test, gs_tree.predict(X_test))**0.5),3)}')\n",
    "print(f'Tree Best Params: {gs_tree.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag R^2 Train:   0.61\n",
      "Bag R^2 Test:    0.303\n",
      "Bag RMSE Train:  14.974\n",
      "Bag RMSE Test:   20.495\n",
      "Bag Best Params: {'bag__max_features': 3, 'bag__max_samples': 0.5, 'bag__n_estimators': 10, 'bag__n_jobs': -1, 'bag__random_state': 42, 'ss__with_mean': False, 'ss__with_std': False}\n"
     ]
    }
   ],
   "source": [
    "print(f'Bag R^2 Train:   {round(gs_bag.score(X_train, y_train),3)}')\n",
    "print(f'Bag R^2 Test:    {round(gs_bag.score(X_test, y_test),3)}')\n",
    "print(f'Bag RMSE Train:  {round((metrics.mean_squared_error(y_train, gs_bag.predict(X_train))**0.5),3)}')\n",
    "print(f'Bag RMSE Test:   {round((metrics.mean_squared_error(y_test, gs_bag.predict(X_test))**0.5),3)}')\n",
    "print(f'Bag Best Params: {gs_bag.best_params_}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe_rf_params = {\n",
    "    'ss__with_mean': [True, False],    ==> True\n",
    "    'ss__with_std': [True, False],     ==> False\n",
    "    'rf__max_depth': [None, 2, 4, 6],  ==> 6\n",
    "    'rf__n_jobs': [2, 4],              ==> 2\n",
    "    'rf__n_estimators': [50, 75, 100], ==> 50\n",
    "    'rf__max_features': [None, 4, 6],  ==> 4\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tree R^2 Train:   0.419\n",
    "Tree R^2 Test:    0.382\n",
    "Tree RMSE Train:  18.274\n",
    "Tree RMSE Test:   19.298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf R^2 Train:   0.451\n",
      "rf R^2 Test:    0.405\n",
      "rf RMSE Train:  17.757\n",
      "rf RMSE Test:   18.926\n",
      "rf Best Params: {'rf__max_depth': 6, 'rf__max_features': 4, 'rf__n_estimators': 50, 'rf__n_jobs': 2, 'ss__with_mean': True, 'ss__with_std': False}\n"
     ]
    }
   ],
   "source": [
    "# Yes this was incorrectly named. Should've been named gs_rf, but instead named gs_pipe. \n",
    "# Don't want to rerun it cause it takes a long time to load so oh well, got the answers anyways\n",
    "\n",
    "print(f'rf R^2 Train:   {round(gs_pipe.score(X_train, y_train),3)}')\n",
    "print(f'rf R^2 Test:    {round(gs_pipe.score(X_test, y_test),3)}')\n",
    "print(f'rf RMSE Train:  {round((metrics.mean_squared_error(y_train, gs_pipe.predict(X_train))**0.5),3)}')\n",
    "print(f'rf RMSE Test:   {round((metrics.mean_squared_error(y_test, gs_pipe.predict(X_test))**0.5),3)}')\n",
    "print(f'rf Best Params: {gs_pipe.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada R^2 Train:   0.204\n",
      "ada R^2 Test:    0.167\n",
      "ada RMSE Train:  21.385\n",
      "ada RMSE Test:   22.398\n",
      "ada Best Params: {'ada__n_estimators': 50, 'ss__with_mean': False, 'ss__with_std': False}\n"
     ]
    }
   ],
   "source": [
    "print(f'ada R^2 Train:   {round(gs_ada.score(X_train, y_train),3)}')\n",
    "print(f'ada R^2 Test:    {round(gs_ada.score(X_test, y_test),3)}')\n",
    "print(f'ada RMSE Train:  {round((metrics.mean_squared_error(y_train, gs_ada.predict(X_train))**0.5),3)}')\n",
    "print(f'ada RMSE Test:   {round((metrics.mean_squared_error(y_test, gs_ada.predict(X_test))**0.5),3)}')\n",
    "print(f'ada Best Params: {gs_ada.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In all of our models, test RMSE is higher than train RMSE, which suggests that there might be an overfitting to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Linear Regression. It has the least overfitting, is easiest to explain, and is much faster. Otherwise, given time to adjust the parameters, we might use ADA or random forest.\n",
    "\n",
    "Cannot use KNN cause cannot identify feature importance.\n",
    "\n",
    "Ans: Random forest. Best RMSE scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Adjust parameters of Tree, Bagging, Random Forest and ADA.\n",
    "2. Get more data (variables) such as the ones listed above (credit score, savings/investments, property ownership)\n",
    "3. Other interaction terms e.g. age * income, etc etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "p401k refers to participation of 401k, which means that they have a 401k. As such, this means that they are eligible for a 401k since they already have it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "All yes for the same reason\n",
    "1. Logistic Regression                  ==> Yes, we are finding a binary classification problem\n",
    "2. KNN Model                            ==> Yes, same\n",
    "3. DTree\n",
    "4. Bagging\n",
    "5. Random Forests\n",
    "6. ADA Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['e401k', 'p401k'])\n",
    "y = df['e401k']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('log', LogisticRegression())]),\n",
       "             param_grid={'log__max_iter': [1000, 2000, 3000],\n",
       "                         'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. log_model Reg Model\n",
    "\n",
    "log = LogisticRegression()\n",
    "ss = StandardScaler()\n",
    "\n",
    "pipe_log_model = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('log', log)\n",
    "])\n",
    "\n",
    "pipe_log_model_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "#     'log__l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n",
    "    'log__max_iter': [1000, 2000, 3000],\n",
    "#     'log__solver': ['sag']\n",
    "}\n",
    "\n",
    "gs_log_model = GridSearchCV(\n",
    "    estimator=pipe_log_model,\n",
    "    param_grid=pipe_log_model_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('log', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'log': LogisticRegression(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'log__C': 1.0,\n",
       " 'log__class_weight': None,\n",
       " 'log__dual': False,\n",
       " 'log__fit_intercept': True,\n",
       " 'log__intercept_scaling': 1,\n",
       " 'log__l1_ratio': None,\n",
       " 'log__max_iter': 100,\n",
       " 'log__multi_class': 'auto',\n",
       " 'log__n_jobs': None,\n",
       " 'log__penalty': 'l2',\n",
       " 'log__random_state': None,\n",
       " 'log__solver': 'lbfgs',\n",
       " 'log__tol': 0.0001,\n",
       " 'log__verbose': 0,\n",
       " 'log__warm_start': False}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_log_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('knn', KNeighborsRegressor())]),\n",
       "             param_grid={'knn__metric': ['euclidean', 'minkowski', 'manhattan'],\n",
       "                         'knn__n_neighbors': [5, 7, 9, 11],\n",
       "                         'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. KNN Model\n",
    "\n",
    "ss = StandardScaler()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "pipe_knn_model = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "pipe_knn_model_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "gs_knn_model = GridSearchCV(\n",
    "    estimator=pipe_knn,\n",
    "    param_grid=pipe_knn_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('knn', KNeighborsClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'knn': KNeighborsClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_knn_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('tree', DecisionTreeRegressor())]),\n",
       "             param_grid={'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False],\n",
       "                         'tree__max_depth': [None, 1, 3, 5],\n",
       "                         'tree__max_features': [None, 1, 3, 5],\n",
       "                         'tree__random_state': [42]})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Decision Tree Model\n",
    "\n",
    "ss = StandardScaler()\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "pipe_tree_model = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('tree', tree)\n",
    "])\n",
    "\n",
    "pipe_tree_model_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "gs_tree_model = GridSearchCV(\n",
    "    estimator=pipe_tree,\n",
    "    param_grid=pipe_tree_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('tree', DecisionTreeClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'tree': DecisionTreeClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'tree__ccp_alpha': 0.0,\n",
       " 'tree__class_weight': None,\n",
       " 'tree__criterion': 'gini',\n",
       " 'tree__max_depth': None,\n",
       " 'tree__max_features': None,\n",
       " 'tree__max_leaf_nodes': None,\n",
       " 'tree__min_impurity_decrease': 0.0,\n",
       " 'tree__min_impurity_split': None,\n",
       " 'tree__min_samples_leaf': 1,\n",
       " 'tree__min_samples_split': 2,\n",
       " 'tree__min_weight_fraction_leaf': 0.0,\n",
       " 'tree__random_state': None,\n",
       " 'tree__splitter': 'best'}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tree_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('tree', DecisionTreeRegressor())]),\n",
       "             param_grid={'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False],\n",
       "                         'tree__max_depth': [None, 1, 3, 5],\n",
       "                         'tree__max_features': [None, 1, 3, 5],\n",
       "                         'tree__random_state': [42]})"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Decision Tree Model\n",
    "\n",
    "ss = StandardScaler()\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "pipe_tree_model = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('tree', tree)\n",
    "])\n",
    "\n",
    "pipe_tree_model_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "gs_tree_model = GridSearchCV(\n",
    "    estimator=pipe_tree,\n",
    "    param_grid=pipe_tree_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('tree', DecisionTreeClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'tree': DecisionTreeClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'tree__ccp_alpha': 0.0,\n",
       " 'tree__class_weight': None,\n",
       " 'tree__criterion': 'gini',\n",
       " 'tree__max_depth': None,\n",
       " 'tree__max_features': None,\n",
       " 'tree__max_leaf_nodes': None,\n",
       " 'tree__min_impurity_decrease': 0.0,\n",
       " 'tree__min_impurity_split': None,\n",
       " 'tree__min_samples_leaf': 1,\n",
       " 'tree__min_samples_split': 2,\n",
       " 'tree__min_weight_fraction_leaf': 0.0,\n",
       " 'tree__random_state': None,\n",
       " 'tree__splitter': 'best'}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tree_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('bag', BaggingRegressor())]),\n",
       "             param_grid={'bag__max_features': [1, 3, 5],\n",
       "                         'bag__max_samples': [0.5, 0.75, 1.0],\n",
       "                         'bag__n_estimators': [3, 5, 10], 'bag__n_jobs': [-1],\n",
       "                         'bag__random_state': [42],\n",
       "                         'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Bagging Model\n",
    "\n",
    "ss = StandardScaler()\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "pipe_bag_model = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('bag', bag)\n",
    "])\n",
    "\n",
    "pipe_bag_model_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "gs_bag_model = GridSearchCV(\n",
    "    estimator=pipe_bag,\n",
    "    param_grid=pipe_bag_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_bag_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('bag', BaggingClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'bag': BaggingClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'bag__base_estimator': None,\n",
       " 'bag__bootstrap': True,\n",
       " 'bag__bootstrap_features': False,\n",
       " 'bag__max_features': 1.0,\n",
       " 'bag__max_samples': 1.0,\n",
       " 'bag__n_estimators': 10,\n",
       " 'bag__n_jobs': None,\n",
       " 'bag__oob_score': False,\n",
       " 'bag__random_state': None,\n",
       " 'bag__verbose': 0,\n",
       " 'bag__warm_start': False}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_bag_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('rf', RandomForestRegressor())]),\n",
       "             param_grid={'rf__max_depth': [None, 2, 4, 6],\n",
       "                         'rf__max_features': [None, 4, 6],\n",
       "                         'rf__n_estimators': [50, 75, 100],\n",
       "                         'rf__n_jobs': [2, 4], 'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Random Forest Model\n",
    "\n",
    "ss = StandardScaler()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "pipe_rf_model = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "pipe_rf_model_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "gs_rf_model = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=pipe_rf_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('ss', StandardScaler()),\n",
       "  ('rf', RandomForestRegressor())],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__ss': StandardScaler(),\n",
       " 'estimator__rf': RandomForestRegressor(),\n",
       " 'estimator__ss__copy': True,\n",
       " 'estimator__ss__with_mean': True,\n",
       " 'estimator__ss__with_std': True,\n",
       " 'estimator__rf__bootstrap': True,\n",
       " 'estimator__rf__ccp_alpha': 0.0,\n",
       " 'estimator__rf__criterion': 'mse',\n",
       " 'estimator__rf__max_depth': None,\n",
       " 'estimator__rf__max_features': 'auto',\n",
       " 'estimator__rf__max_leaf_nodes': None,\n",
       " 'estimator__rf__max_samples': None,\n",
       " 'estimator__rf__min_impurity_decrease': 0.0,\n",
       " 'estimator__rf__min_impurity_split': None,\n",
       " 'estimator__rf__min_samples_leaf': 1,\n",
       " 'estimator__rf__min_samples_split': 2,\n",
       " 'estimator__rf__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__rf__n_estimators': 100,\n",
       " 'estimator__rf__n_jobs': None,\n",
       " 'estimator__rf__oob_score': False,\n",
       " 'estimator__rf__random_state': None,\n",
       " 'estimator__rf__verbose': 0,\n",
       " 'estimator__rf__warm_start': False,\n",
       " 'estimator': Pipeline(steps=[('ss', StandardScaler()), ('rf', RandomForestRegressor())]),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'ss__with_mean': [True, False],\n",
       "  'ss__with_std': [True, False],\n",
       "  'rf__max_depth': [None, 2, 4, 6],\n",
       "  'rf__n_jobs': [2, 4],\n",
       "  'rf__n_estimators': [50, 75, 100],\n",
       "  'rf__max_features': [None, 4, 6]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('ada', AdaBoostClassifier())]),\n",
       "             param_grid={'ada__n_estimators': [50, 100],\n",
       "                         'ss__with_mean': [True, False],\n",
       "                         'ss__with_std': [True, False]})"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. ADA Boost Model\n",
    "\n",
    "ss = StandardScaler()\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "pipe_ada_model = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('ada', ada)\n",
    "])\n",
    "\n",
    "pipe_ada_model_params = {\n",
    "    'ss__with_mean': [True, False],\n",
    "    'ss__with_std': [True, False],\n",
    "    'ada__n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "gs_ada_model = GridSearchCV(\n",
    "    estimator=pipe_ada_model,\n",
    "    param_grid=pipe_ada_model_params,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gs_ada_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('ss', StandardScaler()), ('ada', AdaBoostClassifier())],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__ss': StandardScaler(),\n",
       " 'estimator__ada': AdaBoostClassifier(),\n",
       " 'estimator__ss__copy': True,\n",
       " 'estimator__ss__with_mean': True,\n",
       " 'estimator__ss__with_std': True,\n",
       " 'estimator__ada__algorithm': 'SAMME.R',\n",
       " 'estimator__ada__base_estimator': None,\n",
       " 'estimator__ada__learning_rate': 1.0,\n",
       " 'estimator__ada__n_estimators': 50,\n",
       " 'estimator__ada__random_state': None,\n",
       " 'estimator': Pipeline(steps=[('ss', StandardScaler()), ('ada', AdaBoostClassifier())]),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'ss__with_mean': [True, False],\n",
       "  'ss__with_std': [True, False],\n",
       "  'ada__n_estimators': [50, 100]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ada_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ans: Contextual\n",
    "\n",
    "Minimize false positive: You want to make sure that those are eligible are truly eligible.\n",
    "\n",
    "E.g. Aim is to market properly: Waste funds if market to false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Min FN: Sensitivity\n",
    "Min FP: Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
